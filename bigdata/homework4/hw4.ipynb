{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "apparent-genius",
   "metadata": {},
   "source": [
    "1 Preprocessing (20 pts)\n",
    "\n",
    "Please leave your codes and results in the following sub-questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-guyana",
   "metadata": {},
   "source": [
    "(a) First we will load the data using spark data source API. Write codes to load and print\n",
    "out its schema using printSchema()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intellectual-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.mllib.stat import Statistics\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession.builder.appName('Spark Session 1').getOrCreate()\n",
    "df = spark.read.csv('test.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "previous-interaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test = spark.read.csv('test.csv', header=True)\n",
    "df_train = spark.read.csv('train.csv', header=True)\n",
    "df_test.printSchema()\n",
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-calendar",
   "metadata": {},
   "source": [
    "(b) Find columns that include Missing values. After that, fill the mean value for all the\n",
    "missing values. Please drop Ticket and Cabin columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "egyptian-court",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Embarked', 'Name', 'Fare', 'Pclass', 'SibSp', 'PassengerId', 'Parch', 'Sex', 'Age'}\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "columns = set(df_test.columns) - set(['Ticket', 'Cabin'])\n",
    "print(columns)\n",
    "df_test = df_test.drop('Ticket')\n",
    "df_test = df_test.drop('Cabin')\n",
    "\n",
    "df_train = df_train.drop('Ticket')\n",
    "df_train = df_train.drop('Cabin')\n",
    "#df_train.where(null).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "surface-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_value_count(df):\n",
    "    null_columns_counts = []\n",
    "    numRows = df.count()\n",
    "    for k in df.columns:\n",
    "        nullRows = df.where(col(k).isNull()).count()\n",
    "        if(nullRows > 0):\n",
    "            temp = k,nullRows\n",
    "            null_columns_counts.append(temp)\n",
    "    return(null_columns_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "downtown-germany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Age', 177), ('Embarked', 2)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_columns_count_list = null_value_count(df_train)\n",
    "null_columns_count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "laden-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "mean_Age_train = df_train.select(mean('Age')).collect()[0][0]\n",
    "#mean_Embarked_train = df_train.select(mean('Embarked')).collect()[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "gothic-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "df_train = df_train.na.fill({\"Age\" : mean_Age_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "corrected-connectivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Embarked='Q', count=77),\n",
       " Row(Embarked=None, count=2),\n",
       " Row(Embarked='C', count=168),\n",
       " Row(Embarked='S', count=644)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupBy('Embarked').count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "floral-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.na.fill({'Embarked': '0'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-omaha",
   "metadata": {},
   "source": [
    "(c) Visualize a histogram for an Age column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "horizontal-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "toFloat = ['Survived', 'Age', 'PassengerId', 'Pclass', 'SibSp', 'Parch', 'Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fuzzy-extra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = false)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Embarked: string (nullable = false)\n",
      "\n",
      "root\n",
      " |-- PassengerId: double (nullable = true)\n",
      " |-- Survived: double (nullable = true)\n",
      " |-- Pclass: double (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: double (nullable = true)\n",
      " |-- Parch: double (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()\n",
    "\n",
    "for col in toFloat:\n",
    "    df_train = df_train.withColumn(col, df_train[col].cast(\"double\").alias(col))\n",
    "\n",
    "\n",
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "helpful-invite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 54.,  46., 177., 346., 118.,  70.,  45.,  24.,   9.,   2.]),\n",
       " array([ 0.42 ,  8.378, 16.336, 24.294, 32.252, 40.21 , 48.168, 56.126,\n",
       "        64.084, 72.042, 80.   ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pyspark\n",
    "from pyspark_dist_explore import hist\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('age')\n",
    "ax.set_ylabel('count')\n",
    "hist(ax, df_train.select('Age'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-extraction",
   "metadata": {},
   "source": [
    "(d) Many columns are categorical variables. So we use one-hot encoding using spark ML\n",
    "pipeline API. In this example, we are using StringIndexer and OneHotEncoder to do\n",
    "that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "extended-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "directed-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = df_train.columns\n",
    "col_list\n",
    "df_train = df_train.drop('Name')\n",
    "str_list = ['Sex', 'Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "absolute-welsh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_a716aae75a45, OneHotEncoder_8c325091adf9]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_stages = []\n",
    "indexers = [StringIndexer(inputCols = [string for string in str_list], outputCols = [string+'_index' for string in str_list])]\n",
    "\n",
    "encoders = [OneHotEncoder(inputCols = [string+'_index' for string in str_list], outputCols = [string+'_vec' for string in str_list])]\n",
    "\n",
    "_stages += indexers\n",
    "_stages += encoders\n",
    "_stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "advisory-binary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_a716aae75a45,\n",
       " OneHotEncoder_8c325091adf9,\n",
       " VectorAssembler_a77a7a4e9dcb]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asm_input = ['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "asm_input += [string + '_index' for string in str_list]\n",
    "vector_assembler = VectorAssembler(inputCols=asm_input, outputCol='features')\n",
    "_stages += [vector_assembler]\n",
    "_stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "demonstrated-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages = _stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-appeal",
   "metadata": {},
   "source": [
    "(e) One we prepared our data, we split the data into two sets: training (80 %) and testing\n",
    "(20 %) datasets. We use Spark’s randomSplit method to get them. Please leave the\n",
    "code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "boolean-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df_train.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "foreign-boxing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696\n",
      "195\n",
      "DataFrame[PassengerId: double, Survived: double, Pclass: double, Sex: string, Age: double, SibSp: double, Parch: double, Fare: double, Embarked: string]\n",
      "DataFrame[PassengerId: double, Survived: double, Pclass: double, Sex: string, Age: double, SibSp: double, Parch: double, Fare: double, Embarked: string]\n"
     ]
    }
   ],
   "source": [
    "print(train.count())\n",
    "print(test.count())\n",
    "print(test)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-deputy",
   "metadata": {},
   "source": [
    "2 Classification using Logistic Regression (20 pts)\n",
    "\n",
    "In this questions below, you will train and test a logistic regression model. Please leave\n",
    "your codes for each part in your report.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-integer",
   "metadata": {},
   "source": [
    "(a) Create stages for all features, which are processed above, and make a pipeline with\n",
    "logistic regression using default parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "expensive-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "talented-chain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_a716aae75a45,\n",
       " OneHotEncoder_8c325091adf9,\n",
       " VectorAssembler_a77a7a4e9dcb,\n",
       " LogisticRegression_13fe042b5307]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol='Survived', featuresCol = 'features')\n",
    "_stages += [lr]\n",
    "_stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "painted-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages = _stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-virus",
   "metadata": {},
   "source": [
    "(b) Fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "classified-contrary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: double, Survived: double, Pclass: double, Sex: string, Age: double, SibSp: double, Parch: double, Fare: double, Embarked: string, Sex_index: double, Embarked_index: double, Sex_vec: vector, Embarked_vec: vector, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pipeline.fit(train)\n",
    "train_predict = model.transform(train).select('*')\n",
    "train_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-cross",
   "metadata": {},
   "source": [
    "(c) Once model is trained, we need to know how it’s performing. So we use precision\n",
    "score as our evaluation metric. Report the result. You can refer to RDD-Evaluation\n",
    "or Precision with Micro option (Scikit-learn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "referenced-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "test_predict = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "empirical-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = test_predict.select('PassengerId', 'probability', 'prediction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "european-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "liquid-teach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7692307692307693"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='Survived', metricName='accuracy')\n",
    "print('train accuracy')\n",
    "evaluator.evaluate(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "brutal-documentary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test presicion\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7696068376068377"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='Survived', metricName='weightedPrecision')\n",
    "print('test presicion')\n",
    "evaluator.evaluate(test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-binary",
   "metadata": {},
   "source": [
    "(d) From the fitted model, please identify which attribute is contributed the most? (Hint:\n",
    "Print the coefficients and intercepts for logistic regression.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "reserved-event",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0001, -1.1853, -0.0377, -0.2417, -0.0621, 0.001, 2.8228, 0.2864])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages[-1].coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-refrigerator",
   "metadata": {},
   "source": [
    "1: PassengerId\n",
    "2: Pclass\n",
    "3: Age\n",
    "4: SibSp\n",
    "5: Parch\n",
    "6: Fare\n",
    "7: Sex_index\n",
    "8: Embarked_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-optimum",
   "metadata": {},
   "source": [
    "the correlation coefficient is related to feature importance. so, if the absolute value of the coefficient is large value not close to zero, it is importance feature of ML model. As a result, the Sex attribute is contributed the most in fitted model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
