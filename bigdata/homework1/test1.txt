data
science
is
an
inter
disciplinary
field
that
uses
scientific
methods
processes
algorithms
and
systems
to
extract
knowledge
and
insights
from
structured
and
unstructured
data
1
2
and
apply
knowledge
and
actionable
insights
from
data
across
a
broad
range
of
application
domains
data
science
is
related
to
data
mining
machine
learning
and
big
data
data
science
is
a
concept
to
unify
statistics
data
analysis
informatics
and
their
related
methods
in
order
to
understand
and
analyze
actual
phenomena
with
data
3
it
uses
techniques
and
theories
drawn
from
many
fields
within
the
context
of
mathematics
statistics
computer
science
information
science
and
domain
knowledge
turing
award
winner
jim
gray
imagined
data
science
as
a
fourth
paradigm
of
science
empirical
theoretical
computational
and
now
data
driven
and
asserted
that
everything
about
science
is
changing
because
of
the
impact
of
information
technology
and
the
data
deluge
4
5
data
science
is
an
interdisciplinary
field
focused
on
extracting
knowledge
from
data
sets
which
are
typically
large
see
big
data
and
applying
the
knowledge
and
actionable
insights
from
data
to
solve
problems
in
a
wide
range
of
application
domains
6
the
field
encompasses
preparing
data
for
analysis
formulating
data
science
problems
analyzing
data
developing
data
driven
solutions
and
presenting
findings
to
inform
high
level
decisions
in
a
broad
range
of
application
domains
as
such
it
incorporates
skills
from
computer
science
statistics
information
science
mathematics
information
visualization
data
integration
graphic
design
complex
systems
communication
and
business
7
8
statistician
nathan
yau
drawing
on
ben
fry
also
links
data
science
to
human
computer
interaction
users
should
be
able
to
intuitively
control
and
explore
data
9
10
in
2015
the
american
statistical
association
identified
database
management
statistics
and
machine
learning
and
distributed
and
parallel
systems
as
the
three
emerging
foundational
professional
communities
11
many
statisticians
including
nate
silver
have
argued
that
data
science
is
not
a
new
field
but
rather
another
name
for
statistics
12
others
argue
that
data
science
is
distinct
from
statistics
because
it
focuses
on
problems
and
techniques
unique
to
digital
data
13
vasant
dhar
writes
that
statistics
emphasizes
quantitative
data
and
description
in
contrast
data
science
deals
with
quantitative
and
qualitative
data
e
g
images
and
emphasizes
prediction
and
action
14
andrew
gelman
of
columbia
university
and
data
scientist
vincent
granville
have
described
statistics
as
a
nonessential
part
of
data
science
15
16
stanford
professor
david
donoho
writes
that
data
science
is
not
distinguished
from
statistics
by
the
size
of
datasets
or
use
of
computing
and
that
many
graduate
programs
misleadingly
advertise
their
analytics
and
statistics
training
as
the
essence
of
a
data
science
program
he
describes
data
science
as
an
applied
field
growing
out
of
traditional
statistics
17
in
summary
data
science
can
be
therefore
described
as
an
applied
branch
of
statistics
in
1962
john
tukey
described
a
field
he
called
data
analysis
which
resembles
modern
data
science
17
in
1985
in
a
lecture
given
to
the
chinese
academy
of
sciences
in
beijing
c
f
jeff
wu
used
the
term
data
science
for
the
first
time
as
an
alternative
name
for
statistics
18
later
attendees
at
a
1992
statistics
symposium
at
the
university
of
montpellier
ii
acknowledged
the
emergence
of
a
new
discipline
focused
on
data
of
various
origins
and
forms
combining
established
concepts
and
principles
of
statistics
and
data
analysis
with
computing
19
20
the
term
data
science
has
been
traced
back
to
1974
when
peter
naur
proposed
it
as
an
alternative
name
for
computer
science
21
in
1996
the
international
federation
of
classification
societies
became
the
first
conference
to
specifically
feature
data
science
as
a
topic
21
however
the
definition
was
still
in
flux
after
the
1985
lecture
in
the
chinese
academy
of
sciences
in
beijing
in
1997
c
f
jeff
wu
again
suggested
that
statistics
should
be
renamed
data
science
he
reasoned
that
a
new
name
would
help
statistics
shed
inaccurate
stereotypes
such
as
being
synonymous
with
accounting
or
limited
to
describing
data
22
in
1998
chikio
hayashi
argued
for
data
science
as
a
new
interdisciplinary
concept
with
three
aspects
data
design
collection
and
analysis
20
during
the
1990s
popular
terms
for
the
process
of
finding
patterns
in
datasets
which
were
increasingly
large
included
knowledge
discovery
and
data
mining
23
21
the
modern
conception
of
data
science
as
an
independent
discipline
is
sometimes
attributed
to
william
s
cleveland
24
in
a
2001
paper
he
advocated
an
expansion
of
statistics
beyond
theory
into
technical
areas
because
this
would
significantly
change
the
field
it
warranted
a
new
name
23
data
science
became
more
widely
used
in
the
next
few
years
in
2002
the
committee
on
data
for
science
and
technology
launched
data
science
journal
in
2003
columbia
university
launched
the
journal
of
data
science
23
in
2014
the
american
statistical
association
s
section
on
statistical
learning
and
data
mining
changed
its
name
to
the
section
on
statistical
learning
and
data
science
reflecting
the
ascendant
popularity
of
data
science
25
the
professional
title
of
data
scientist
has
been
attributed
to
dj
patil
and
jeff
hammerbacher
in
2008
26
though
it
was
used
by
the
national
science
board
in
their
2005
report
long
lived
digital
data
collections
enabling
research
and
education
in
the
21st
century
it
referred
broadly
to
any
key
role
in
managing
a
digital
data
collection
27
there
is
still
no
consensus
on
the
definition
of
data
science
and
it
is
considered
by
some
to
be
a
buzzword
28
big
data
is
very
quickly
becoming
a
vital
tool
for
businesses
and
companies
of
all
sizes
29
the
availability
and
interpretation
of
big
data
has
altered
the
business
models
of
old
industries
and
enabled
the
creation
of
new
ones
29
data
driven
businesses
are
worth
1
2
trillion
collectively
in
2020
an
increase
from
333
billion
in
the
year
2015
30
data
scientists
are
responsible
for
breaking
down
big
data
into
usable
information
and
creating
software
and
algorithms
that
help
companies
and
organizations
determine
optimal
operations
30
as
big
data
continues
to
have
a
major
impact
on
the
world
data
science
does
as
well
due
to
the
close
relationship
between
the
two
30
there
are
a
variety
of
different
technologies
and
techniques
that
are
used
for
data
science
which
depend
on
the
application
more
recently
full
featured
end
to
end
platforms
have
been
developed
and
heavily
used
for
data
science
and
machine
learning



big
data
is
a
field
that
treats
ways
to
analyze
systematically
extract
information
from
or
otherwise
deal
with
data
sets
that
are
too
large
or
complex
to
be
dealt
with
by
traditional
data
processing
application
software
data
with
many
fields
columns
offer
greater
statistical
power
while
data
with
higher
complexity
more
attributes
or
columns
may
lead
to
a
higher
false
discovery
rate
2
big
data
analysis
challenges
include
capturing
data
data
storage
data
analysis
search
sharing
transfer
visualization
querying
updating
information
privacy
and
data
source
big
data
was
originally
associated
with
three
key
concepts
volume
variety
and
velocity
the
analysis
of
big
data
presents
challenges
in
sampling
and
thus
previously
allowing
for
only
observations
and
sampling
therefore
big
data
often
includes
data
with
sizes
that
exceed
the
capacity
of
traditional
software
to
process
within
an
acceptable
time
and
value
current
usage
of
the
term
big
data
tends
to
refer
to
the
use
of
predictive
analytics
user
behavior
analytics
or
certain
other
advanced
data
analytics
methods
that
extract
value
from
big
data
and
seldom
to
a
particular
size
of
data
set
there
is
little
doubt
that
the
quantities
of
data
now
available
are
indeed
large
but
that
s
not
the
most
relevant
characteristic
of
this
new
data
ecosystem
3
analysis
of
data
sets
can
find
new
correlations
to
spot
business
trends
prevent
diseases
combat
crime
and
so
on
4
scientists
business
executives
medical
practitioners
advertising
and
governments
alike
regularly
meet
difficulties
with
large
data
sets
in
areas
including
internet
searches
fintech
healthcare
analytics
geographic
information
systems
urban
informatics
and
business
informatics
scientists
encounter
limitations
in
e
science
work
including
meteorology
genomics
5
connectomics
complex
physics
simulations
biology
and
environmental
research
6
the
size
and
number
of
available
data
sets
has
grown
rapidly
as
data
is
collected
by
devices
such
as
mobile
devices
cheap
and
numerous
information
sensing
internet
of
things
devices
aerial
remote
sensing
software
logs
cameras
microphones
radio
frequency
identification
rfid
readers
and
wireless
sensor
networks
7
8
the
world
s
technological
per
capita
capacity
to
store
information
has
roughly
doubled
every
40
months
since
the
1980s
9
as
of
2012
update
every
day
2
5
exabytes
2
5
260
bytes
of
data
are
generated
10
based
on
an
idc
report
prediction
the
global
data
volume
was
predicted
to
grow
exponentially
from
4
4
zettabytes
to
44
zettabytes
between
2013
and
2020
by
2025
idc
predicts
there
will
be
163
zettabytes
of
data
11
one
question
for
large
enterprises
is
determining
who
should
own
big
data
initiatives
that
affect
the
entire
organization
12
relational
database
management
systems
and
desktop
statistical
software
packages
used
to
visualize
data
often
have
difficulty
processing
and
analyzing
big
data
the
processing
and
analysis
of
big
data
may
require
massively
parallel
software
running
on
tens
hundreds
or
even
thousands
of
servers
13
what
qualifies
as
big
data
varies
depending
on
the
capabilities
of
those
analyzing
it
and
their
tools
furthermore
expanding
capabilities
make
big
data
a
moving
target
for
some
organizations
facing
hundreds
of
gigabytes
of
data
for
the
first
time
may
trigger
a
need
to
reconsider
data
management
options
for
others
it
may
take
tens
or
hundreds
of
terabytes
before
data
size
becomes
a
significant
consideration
14
the
term
big
data
has
been
in
use
since
the
1990s
with
some
giving
credit
to
john
mashey
for
popularizing
the
term
15
16
big
data
usually
includes
data
sets
with
sizes
beyond
the
ability
of
commonly
used
software
tools
to
capture
curate
manage
and
process
data
within
a
tolerable
elapsed
time
17
big
data
philosophy
encompasses
unstructured
semi
structured
and
structured
data
however
the
main
focus
is
on
unstructured
data
18
big
data
size
is
a
constantly
moving
target
as
of
2012
update
ranging
from
a
few
dozen
terabytes
to
many
zettabytes
of
data
19
big
data
requires
a
set
of
techniques
and
technologies
with
new
forms
of
integration
to
reveal
insights
from
data
sets
that
are
diverse
complex
and
of
a
massive
scale
20
variety
veracity
and
various
other
vs
are
added
by
some
organizations
to
describe
it
a
revision
challenged
by
some
industry
authorities
21
the
vs
of
big
data
were
often
referred
to
as
the
three
vs
four
vs
and
five
vs
they
represented
the
qualities
of
big
data
in
volume
variety
velocity
veracity
and
value
22
variability
is
often
included
as
an
additional
quality
of
big
data
a
2018
definition
states
big
data
is
where
parallel
computing
tools
are
needed
to
handle
data
and
notes
this
represents
a
distinct
and
clearly
defined
change
in
the
computer
science
used
via
parallel
programming
theories
and
losses
of
some
of
the
guarantees
and
capabilities
made
by
codd
s
relational
model
23
the
growing
maturity
of
the
concept
more
starkly
delineates
the
difference
between
big
data
and
business
intelligence
24
big
data
can
be
described
by
the
following
characteristics
other
possible
characteristics
of
big
data
are
33
big
data
repositories
have
existed
in
many
forms
often
built
by
corporations
with
a
special
need
commercial
vendors
historically
offered
parallel
database
management
systems
for
big
data
beginning
in
the
1990s
for
many
years
wintercorp
published
the
largest
database
report
34
promotional
source
teradata
corporation
in
1984
marketed
the
parallel
processing
dbc
1012
system
teradata
systems
were
the
first
to
store
and
analyze
1
terabyte
of
data
in
1992
hard
disk
drives
were
2
5
gb
in
1991
so
the
definition
of
big
data
continuously
evolves
according
to
kryder
s
law
teradata
installed
the
first
petabyte
class
rdbms
based
system
in
2007
as
of
2017
update
there
are
a
few
dozen
petabyte
class
teradata
relational
databases
installed
the
largest
of
which
exceeds
50
pb
systems
up
until
2008
were
100
structured
relational
data
since
then
teradata
has
added
unstructured
data
types
including
xml
json
and
avro
in
2000
seisint
inc
now
lexisnexis
risk
solutions
developed
a
c
based
distributed
platform
for
data
processing
and
querying
known
as
the
hpcc
systems
platform
this
system
automatically
partitions
distributes
stores
and
delivers
structured
semi
structured
and
unstructured
data
across
multiple
commodity
servers
users
can
write
data
processing
pipelines
and
queries
in
a
declarative
dataflow
programming
language
called
ecl
data
analysts
working
in
ecl
are
not
required
to
define
data
schemas
upfront
and
can
rather
focus
on
the
particular
problem
at
hand
reshaping
data
in
the
best
possible
manner
as
they
develop
the
solution
in
2004
lexisnexis
acquired
seisint
inc
35
and
their
high
speed
parallel
processing
platform
and
successfully
used
this
platform
to
integrate
the
data
systems
of
choicepoint
inc
when
they
acquired
that
company
in
2008
36
in
2011
the
hpcc
systems
platform
was
open
sourced
under
the
apache
v2
0
license
cern
and
other
physics
experiments
have
collected
big
data
sets
for
many
decades
usually
analyzed
via
high
throughput
computing
rather
than
the
map
reduce
architectures
usually
meant
by
the
current
big
data
movement
in
2004
google
published
a
paper
on
a
process
called
mapreduce
that
uses
a
similar
architecture
the
mapreduce
concept
provides
a
parallel
processing
model
and
an
associated
implementation
was
released
to
process
huge
amounts
of
data
with
mapreduce
queries
are
split
and
distributed
across
parallel
nodes
and
processed
in
parallel
the
map
step
the
results
are
then
gathered
and
delivered
the
reduce
step
the
framework
was
very
successful
37
so
others
wanted
to
replicate
the
algorithm
therefore
an
implementation
of
the
mapreduce
framework
was
adopted
by
an
apache
open
source
project
named
hadoop
38
apache
spark
was
developed
in
2012
in
response
to
limitations
in
the
mapreduce
paradigm
as
it
adds
the
ability
to
set
up
many
operations
not
just
map
followed
by
reducing
mike2
0
is
an
open
approach
to
information
management
that
acknowledges
the
need
for
revisions
due
to
big
data
implications
identified
in
an
article
titled
big
data
solution
offering
39
the
methodology
addresses
handling
big
data
in
terms
of
useful
permutations
of
data
sources
complexity
in
interrelationships
and
difficulty
in
deleting
or
modifying
individual
records
40
studies
in
2012
showed
that
a
multiple
layer
architecture
was
one
option
to
address
the
issues
that
big
data
presents
a
distributed
parallel
architecture
distributes
data
across
multiple
servers
these
parallel
execution
environments
can
dramatically
improve
data
processing
speeds
this
type
of
architecture
inserts
data
into
a
parallel
dbms
which
implements
the
use
of
mapreduce
and
hadoop
frameworks
this
type
of
framework
looks
to
make
the
processing
power
transparent
to
the
end
user
by
using
a
front
end
application
server
41
the
data
lake
allows
an
organization
to
shift
its
focus
from
centralized
control
to
a
shared
model
to
respond
to
the
changing
dynamics
of
information
management
this
enables
quick
segregation
of
data
into
the
data
lake
thereby
reducing
the
overhead
time
42
43
a
2011
mckinsey
global
institute
report
characterizes
the
main
components
and
ecosystem
of
big
data
as
follows
44
multidimensional
big
data
can
also
be
represented
as
olap
data
cubes
or
mathematically
tensors
array
database
systems
have
set
out
to
provide
storage
and
high
level
query
support
on
this
data
type
additional
technologies
being
applied
to
big
data
include
efficient
tensor
based
computation
45
such
as
multilinear
subspace
learning
46
massively
parallel
processing
mpp
databases
search
based
applications
data
mining
47
distributed
file
systems
distributed
cache
e
g
burst
buffer
and
memcached
distributed
databases
cloud
and
hpc
based
infrastructure
applications
storage
and
computing
resources
48
and
the
internet
citation
needed
although
many
approaches
and
technologies
have
been
developed
it
still
remains
difficult
to
carry
out
machine
learning
with
big
data
49
some
mpp
relational
databases
have
the
ability
to
store
and
manage
petabytes
of
data
implicit
is
the
ability
to
load
monitor
back
up
and
optimize
the
use
of
the
large
data
tables
in
the
rdbms
50
promotional
source
darpa
s
topological
data
analysis
program
seeks
the
fundamental
structure
of
massive
data
sets
and
in
2008
the
technology
went
public
with
the
launch
of
a
company
called
ayasdi
51
third
party
source
needed
the
practitioners
of
big
data
analytics
processes
are
generally
hostile
to
slower
shared
storage
52
preferring
direct
attached
storage
das
in
its
various
forms
from
solid
state
drive
ssd
to
high
capacity
sata
disk
buried
inside
parallel
processing
nodes
the
perception
of
shared
storage
architectures
storage
area
network
san
and
network
attached
storage
nas
is
that
they
are
relatively
slow
complex
and
expensive
these
qualities
are
not
consistent
with
big
data
analytics
systems
that
thrive
on
system
performance
commodity
infrastructure
and
low
cost
real
or
near
real
time
information
delivery
is
one
of
the
defining
characteristics
of
big
data
analytics
latency
is
therefore
avoided
whenever
and
wherever
possible
data
in
direct
attached
memory
or
disk
is
good
data
on
memory
or
disk
at
the
other
end
of
an
fc
san
connection
is
not
the
cost
of
an
san
at
the
scale
needed
for
analytics
applications
is
much
higher
than
other
storage
techniques
there
are
advantages
as
well
as
disadvantages
to
shared
storage
in
big
data
analytics
but
big
data
analytics
practitioners
as
of
2011
update
did
not
favor
it
53
promotional
source
big
data
has
increased
the
demand
of
information
management
specialists
so
much
so
that
software
ag
oracle
corporation
ibm
microsoft
sap
emc
hp
and
dell
have
spent
more
than
15
billion
on
software
firms
specializing
in
data
management
and
analytics
in
2010
this
industry
was
worth
more
than
100
billion
and
was
growing
at
almost
10
percent
a
year
about
twice
as
fast
as
the
software
business
as
a
whole
4
developed
economies
increasingly
use
data
intensive
technologies
there
are
4
6
billion
mobile
phone
subscriptions
worldwide
and
between
1
billion
and
2
billion
people
accessing
the
internet
4
between
1990
and
2005
more
than
1
billion
people
worldwide
entered
the
middle
class
which
means
more
people
became
more
literate
which
in
turn
led
to
information
growth
the
world
s
effective
capacity
to
exchange
information
through
telecommunication
networks
was
281
petabytes
in
1986
471
petabytes
in
1993
2
2
exabytes
in
2000
65
exabytes
in
2007
9
and
predictions
put
the
amount
of
internet
traffic
at
667
exabytes
annually
by
2014
4
according
to
one
estimate
one
third
of
the
globally
stored
information
is
in
the
form
of
alphanumeric
text
and
still
image
data
54
which
is
the
format
most
useful
for
most
big
data
applications
this
also
shows
the
potential
of
yet
unused
data
i
e
in
the
form
of
video
and
audio
content
while
many
vendors
offer
off
the
shelf
solutions
for
big
data
experts
recommend
the
development
of
in
house
solutions
custom
tailored
to
solve
the
company
s
problem
at
hand
if
the
company
has
sufficient
technical
capabilities
55
the
use
and
adoption
of
big
data
within
governmental
processes
allows
efficiencies
in
terms
of
cost
productivity
and
innovation
56
but
does
not
come
without
its
flaws
data
analysis
often
requires
multiple
parts
of
government
central
and
local
to
work
in
collaboration
and
create
new
and
innovative
processes
to
deliver
the
desired
outcome
a
common
government
organization
that
makes
use
of
big
data
is
the
national
security
administration
nsa
who
monitor
the
activities
of
the
internet
constantly
in
search
for
potential
patterns
of
suspicious
or
illegal
activities
their
system
may
pick
up
civil
registration
and
vital
statistics
crvs
collects
all
certificates
status
from
birth
to
death
crvs
is
a
source
of
big
data
for
governments
research
on
the
effective
usage
of
information
and
communication
technologies
for
development
also
known
as
ict4d
suggests
that
big
data
technology
can
make
important
contributions
but
also
present
unique
challenges
to
international
development
57
58
advancements
in
big
data
analysis
offer
cost
effective
opportunities
to
improve
decision
making
in
critical
development
areas
such
as
health
care
employment
economic
productivity
crime
security
and
natural
disaster
and
resource
management
59
60
61
additionally
user
generated
data
offers
new
opportunities
to
give
the
unheard
a
voice
62
however
longstanding
challenges
for
developing
regions
such
as
inadequate
technological
infrastructure
and
economic
and
human
resource
scarcity
exacerbate
existing
concerns
with
big
data
such
as
privacy
imperfect
methodology
and
interoperability
issues
59
the
challenge
of
big
data
for
development
59
is
currently
evolving
toward
the
application
of
this
data
through
machine
learning
known
as
artificial
intelligence
for
development
ai4d
63
a
major
practical
application
of
big
data
for
development
has
been
fighting
poverty
with
data
64
in
2015
blumenstock
and
colleagues
estimated
predicted
poverty
and
wealth
from
mobile
phone
metadata
65
and
in
2016
jean
and
colleagues
combined
satellite
imagery
and
machine
learning
to
predict
poverty
66
using
digital
trace
data
to
study
the
labor
market
and
the
digital
economy
in
latin
america
hilbert
and
colleagues
67
68
argue
that
digital
trace
data
has
several
benefits
such
as
at
the
same
time
working
with
digital
trace
data
instead
of
traditional
survey
data
does
not
eliminate
the
traditional
challenges
involved
when
working
in
the
field
of
international
quantitative
analysis
priorities
change
but
the
basic
discussions
remain
the
same
among
the
main
challenges
are
big
data
analytics
has
helped
healthcare
improve
by
providing
personalized
medicine
and
prescriptive
analytics
clinical
risk
intervention
and
predictive
analytics
waste
and
care
variability
reduction
automated
external
and
internal
reporting
of
patient
data
standardized
medical
terms
and
patient
registries
and
fragmented
point
solutions
69
70
71
72
some
areas
of
improvement
are
more
aspirational
than
actually
implemented
the
level
of
data
generated
within
healthcare
systems
is
not
trivial
with
the
added
adoption
of
mhealth
ehealth
and
wearable
technologies
the
volume
of
data
will
continue
to
increase
this
includes
electronic
health
record
data
imaging
data
patient
generated
data
sensor
data
and
other
forms
of
difficult
to
process
data
there
is
now
an
even
greater
need
for
such
environments
to
pay
greater
attention
to
data
and
information
quality
73
big
data
very
often
means
dirty
data
and
the
fraction
of
data
inaccuracies
increases
with
data
volume
growth
human
inspection
at
the
big
data
scale
is
impossible
and
there
is
a
desperate
need
in
health
service
for
intelligent
tools
for
accuracy
and
believability
control
and
handling
of
information
missed
74
while
extensive
information
in
healthcare
is
now
electronic
it
fits
under
the
big
data
umbrella
as
most
is
unstructured
and
difficult
to
use
75
the
use
of
big
data
in
healthcare
has
raised
significant
ethical
challenges
ranging
from
risks
for
individual
rights
privacy
and
autonomy
to
transparency
and
trust
76
big
data
in
health
research
is
particularly
promising
in
terms
of
exploratory
biomedical
research
as
data
driven
analysis
can
move
forward
more
quickly
than
hypothesis
driven
research
77
then
trends
seen
in
data
analysis
can
be
tested
in
traditional
hypothesis
driven
follow
up
biological
research
and
eventually
clinical
research
a
related
application
sub
area
that
heavily
relies
on
big
data
within
the
healthcare
field
is
that
of
computer
aided
diagnosis
in
medicine
78
for
instance
for
epilepsy
monitoring
it
is
customary
to
create
5
to
10
gb
of
data
daily
79
similarly
a
single
uncompressed
image
of
breast
tomosynthesis
averages
450
mb
of
data
80
these
are
just
few
of
the
many
examples
where
computer
aided
diagnosis
uses
big
data
for
this
reason
big
data
has
been
recognized
as
one
of
the
seven
key
challenges
that
computer
aided
diagnosis
systems
need
to
overcome
in
order
to
reach
the
next
level
of
performance
81
a
mckinsey
global
institute
study
found
a
shortage
of
1
5
million
highly
trained
data
professionals
and
managers
44
and
a
number
of
universities
82
better
source
needed
including
university
of
tennessee
and
uc
berkeley
have
created
masters
programs
to
meet
this
demand
private
boot
camps
have
also
developed
programs
to
meet
that
demand
including
free
programs
like
the
data
incubator
or
paid
programs
like
general
assembly
83
in
the
specific
field
of
marketing
one
of
the
problems
stressed
by
wedel
and
kannan
84
is
that
marketing
has
several
sub
domains
e
g
advertising
promotions
product
development
branding
that
all
use
different
types
of
data
because
one
size
fits
all
analytical
solutions
are
not
desirable
business
schools
should
prepare
marketing
managers
to
have
wide
knowledge
on
all
the
different
techniques
used
in
these
subdomains
to
get
a
big
picture
and
work
effectively
with
analysts
to
understand
how
the
media
uses
big
data
it
is
first
necessary
to
provide
some
context
into
the
mechanism
used
for
media
process
it
has
been
suggested
by
nick
couldry
and
joseph
turow
that
practitioners
in
media
and
advertising
approach
big
data
as
many
actionable
points
of
information
about
millions
of
individuals
the
industry
appears
to
be
moving
away
from
the
traditional
approach
of
using
specific
media
environments
such
as
newspapers
magazines
or
television
shows
and
instead
taps
into
consumers
with
technologies
that
reach
targeted
people
at
optimal
times
in
optimal
locations
the
ultimate
aim
is
to
serve
or
convey
a
message
or
content
that
is
statistically
speaking
in
line
with
the
consumer
s
mindset
for
example
publishing
environments
are
increasingly
tailoring
messages
advertisements
and
content
articles
to
appeal
to
consumers
that
have
been
exclusively
gleaned
through
various
data
mining
activities
85
channel
4
the
british
public
service
television
broadcaster
is
a
leader
in
the
field
of
big
data
and
data
analysis
87
health
insurance
providers
are
collecting
data
on
social
determinants
of
health
such
as
food
and
tv
consumption
marital
status
clothing
size
and
purchasing
habits
from
which
they
make
predictions
on
health
costs
in
order
to
spot
health
issues
in
their
clients
it
is
controversial
whether
these
predictions
are
currently
being
used
for
pricing
88
big
data
and
the
iot
work
in
conjunction
data
extracted
from
iot
devices
provides
a
mapping
of
device
inter
connectivity
such
mappings
have
been
used
by
the
media
industry
companies
and
governments
to
more
accurately
target
their
audience
and
increase
media
efficiency
the
iot
is
also
increasingly
adopted
as
a
means
of
gathering
sensory
data
and
this
sensory
data
has
been
used
in
medical
89
manufacturing
90
and
transportation
91
contexts
kevin
ashton
the
digital
innovation
expert
who
is
credited
with
coining
the
term
92
defines
the
internet
of
things
in
this
quote
if
we
had
computers
that
knew
everything
there
was
to
know
about
things
using
data
they
gathered
without
any
help
from
us
we
would
be
able
to
track
and
count
everything
and
greatly
reduce
waste
loss
and
cost
we
would
know
when
things
needed
replacing
repairing
or
recalling
and
whether
they
were
fresh
or
past
their
best
especially
since
2015
big
data
has
come
to
prominence
within
business
operations
as
a
tool
to
help
employees
work
more
efficiently
and
streamline
the
collection
and
distribution
of
information
technology
it
the
use
of
big
data
to
resolve
it
and
data
collection
issues
within
an
enterprise
is
called
it
operations
analytics
itoa
93
by
applying
big
data
principles
into
the
concepts
of
machine
intelligence
and
deep
computing
it
departments
can
predict
potential
issues
and
move
to
provide
solutions
before
the
problems
even
happen
93
in
this
time
itoa
businesses
were
also
beginning
to
play
a
major
role
in
systems
management
by
offering
platforms
that
brought
individual
data
silos
together
and
generated
insights
from
the
whole
of
the
system
rather
than
from
isolated
pockets
of
data
examples
of
uses
of
big
data
in
public
services
big
data
can
be
used
to
improve
training
and
understanding
competitors
using
sport
sensors
it
is
also
possible
to
predict
winners
in
a
match
using
big
data
analytics
132
future
performance
of
players
could
be
predicted
as
well
thus
players
value
and
salary
is
determined
by
data
collected
throughout
the
season
133
in
formula
one
races
race
cars
with
hundreds
of
sensors
generate
terabytes
of
data
these
sensors
collect
data
points
from
tire
pressure
to
fuel
burn
efficiency
134
based
on
the
data
engineers
and
data
analysts
decide
whether
adjustments
should
be
made
in
order
to
win
a
race
besides
using
big
data
race
teams
try
to
predict
the
time
they
will
finish
the
race
beforehand
based
on
simulations
using
data
collected
over
the
season
135
during
the
covid
19
pandemic
big
data
was
raised
as
a
way
to
minimise
the
impact
of
the
disease
significant
applications
of
big
data
included
minimising
the
spread
of
the
virus
case
identification
and
development
of
medical
treatment
141
governments
used
big
data
to
track
infected
people
to
minimise
spread
early
adopters
included
china
taiwan
south
korea
and
israel
142
143
144
encrypted
search
and
cluster
formation
in
big
data
were
demonstrated
in
march
2014
at
the
american
society
of
engineering
education
gautam
siwach
engaged
at
tackling
the
challenges
of
big
data
by
mit
computer
science
and
artificial
intelligence
laboratory
and
amir
esmailpour
at
the
unh
research
group
investigated
the
key
features
of
big
data
as
the
formation
of
clusters
and
their
interconnections
they
focused
on
the
security
of
big
data
and
the
orientation
of
the
term
towards
the
presence
of
different
types
of
data
in
an
encrypted
form
at
cloud
interface
by
providing
the
raw
definitions
and
real
time
examples
within
the
technology
moreover
they
proposed
an
approach
for
identifying
the
encoding
technique
to
advance
towards
an
expedited
search
over
encrypted
text
leading
to
the
security
enhancements
in
big
data
145
in
march
2012
the
white
house
announced
a
national
big
data
initiative
that
consisted
of
six
federal
departments
and
agencies
committing
more
than
200
million
to
big
data
research
projects
146
the
initiative
included
a
national
science
foundation
expeditions
in
computing
grant
of
10
million
over
five
years
to
the
amplab
147
at
the
university
of
california
berkeley
148
the
amplab
also
received
funds
from
darpa
and
over
a
dozen
industrial
sponsors
and
uses
big
data
to
attack
a
wide
range
of
problems
from
predicting
traffic
congestion
149
to
fighting
cancer
150
the
white
house
big
data
initiative
also
included
a
commitment
by
the
department
of
energy
to
provide
25
million
in
funding
over
five
years
to
establish
the
scalable
data
management
analysis
and
visualization
sdav
institute
151
led
by
the
energy
department
s
lawrence
berkeley
national
laboratory
the
sdav
institute
aims
to
bring
together
the
expertise
of
six
national
laboratories
and
seven
universities
to
develop
new
tools
to
help
scientists
manage
and
visualize
data
on
the
department
s
supercomputers
the
u
s
state
of
massachusetts
announced
the
massachusetts
big
data
initiative
in
may
2012
which
provides
funding
from
the
state
government
and
private
companies
to
a
variety
of
research
institutions
152
the
massachusetts
institute
of
technology
hosts
the
intel
science
and
technology
center
for
big
data
in
the
mit
computer
science
and
artificial
intelligence
laboratory
combining
government
corporate
and
institutional
funding
and
research
efforts
153
the
european
commission
is
funding
the
two
year
long
big
data
public
private
forum
through
their
seventh
framework
program
to
engage
companies
academics
and
other
stakeholders
in
discussing
big
data
issues
the
project
aims
to
define
a
strategy
in
terms
of
research
and
innovation
to
guide
supporting
actions
from
the
european
commission
in
the
successful
implementation
of
the
big
data
economy
outcomes
of
this
project
will
be
used
as
input
for
horizon
2020
their
next
framework
program
154
the
british
government
announced
in
march
2014
the
founding
of
the
alan
turing
institute
named
after
the
computer
pioneer
and
code
breaker
which
will
focus
on
new
ways
to
collect
and
analyze
large
data
sets
155
at
the
university
of
waterloo
stratford
campus
canadian
open
data
experience
code
inspiration
day
participants
demonstrated
how
using
data
visualization
can
increase
the
understanding
and
appeal
of
big
data
sets
and
communicate
their
story
to
the
world
156
computational
social
sciences
anyone
can
use
application
programming
interfaces
apis
provided
by
big
data
holders
such
as
google
and
twitter
to
do
research
in
the
social
and
behavioral
sciences
157
often
these
apis
are
provided
for
free
157
tobias
preis
et
al
used
google
trends
data
to
demonstrate
that
internet
users
from
countries
with
a
higher
per
capita
gross
domestic
products
gdps
are
more
likely
to
search
for
information
about
the
future
than
information
about
the
past
the
findings
suggest
there
may
be
a
link
between
online
behaviors
and
real
world
economic
indicators
158
159
160
the
authors
of
the
study
examined
google
queries
logs
made
by
ratio
of
the
volume
of
searches
for
the
coming
year
2011
to
the
volume
of
searches
for
the
previous
year
2009
which
they
call
the
future
orientation
index
161
they
compared
the
future
orientation
index
to
the
per
capita
gdp
of
each
country
and
found
a
strong
tendency
for
countries
where
google
users
inquire
more
about
the
future
to
have
a
higher
gdp
tobias
preis
and
his
colleagues
helen
susannah
moat
and
h
eugene
stanley
introduced
a
method
to
identify
online
precursors
for
stock
market
moves
using
trading
strategies
based
on
search
volume
data
provided
by
google
trends
162
their
analysis
of
google
search
volume
for
98
terms
of
varying
financial
relevance
published
in
scientific
reports
163
suggests
that
increases
in
search
volume
for
financially
relevant
search
terms
tend
to
precede
large
losses
in
financial
markets
164
165
166
167
168
169
170
big
data
sets
come
with
algorithmic
challenges
that
previously
did
not
exist
hence
there
is
seen
by
some
to
be
a
need
to
fundamentally
change
the
processing
ways
171
the
workshops
on
algorithms
for
modern
massive
data
sets
mmds
bring
together
computer
scientists
statisticians
mathematicians
and
data
analysis
practitioners
to
discuss
algorithmic
challenges
of
big
data
172
regarding
big
data
such
concepts
of
magnitude
are
relative
as
it
is
stated
if
the
past
is
of
any
guidance
then
today
s
big
data
most
likely
will
not
be
considered
as
such
in
the
near
future
78
a
research
question
that
is
asked
about
big
data
sets
is
whether
it
is
necessary
to
look
at
the
full
data
to
draw
certain
conclusions
about
the
properties
of
the
data
or
if
is
a
sample
is
good
enough
the
name
big
data
itself
contains
a
term
related
to
size
and
this
is
an
important
characteristic
of
big
data
but
sampling
enables
the
selection
of
right
data
points
from
within
the
larger
data
set
to
estimate
the
characteristics
of
the
whole
population
in
manufacturing
different
types
of
sensory
data
such
as
acoustics
vibration
pressure
current
voltage
and
controller
data
are
available
at
short
time
intervals
to
predict
downtime
it
may
not
be
necessary
to
look
at
all
the
data
but
a
sample
may
be
sufficient
big
data
can
be
broken
down
by
various
data
point
categories
such
as
demographic
psychographic
behavioral
and
transactional
data
with
large
sets
of
data
points
marketers
are
able
to
create
and
use
more
customized
segments
of
consumers
for
more
strategic
targeting
there
has
been
some
work
done
in
sampling
algorithms
for
big
data
a
theoretical
formulation
for
sampling
twitter
data
has
been
developed
173
critiques
of
the
big
data
paradigm
come
in
two
flavors
those
that
question
the
implications
of
the
approach
itself
and
those
that
question
the
way
it
is
currently
done
174
one
approach
to
this
criticism
is
the
field
of
critical
data
studies
a
crucial
problem
is
that
we
do
not
know
much
about
the
underlying
empirical
micro
processes
that
lead
to
the
emergence
of
the
se
typical
network
characteristics
of
big
data
17
in
their
critique
snijders
matzat
and
reips
point
out
that
often
very
strong
assumptions
are
made
about
mathematical
properties
that
may
not
at
all
reflect
what
is
really
going
on
at
the
level
of
micro
processes
mark
graham
has
leveled
broad
critiques
at
chris
anderson
s
assertion
that
big
data
will
spell
the
end
of
theory
175
focusing
in
particular
on
the
notion
that
big
data
must
always
be
contextualized
in
their
social
economic
and
political
contexts
176
even
as
companies
invest
eight
and
nine
figure
sums
to
derive
insight
from
information
streaming
in
from
suppliers
and
customers
less
than
40
of
employees
have
sufficiently
mature
processes
and
skills
to
do
so
to
overcome
this
insight
deficit
big
data
no
matter
how
comprehensive
or
well
analyzed
must
be
complemented
by
big
judgment
according
to
an
article
in
the
harvard
business
review
177
much
in
the
same
line
it
has
been
pointed
out
that
the
decisions
based
on
the
analysis
of
big
data
are
inevitably
informed
by
the
world
as
it
was
in
the
past
or
at
best
as
it
currently
is
59
fed
by
a
large
number
of
data
on
past
experiences
algorithms
can
predict
future
development
if
the
future
is
similar
to
the
past
178
if
the
system
s
dynamics
of
the
future
change
if
it
is
not
a
stationary
process
the
past
can
say
little
about
the
future
in
order
to
make
predictions
in
changing
environments
it
would
be
necessary
to
have
a
thorough
understanding
of
the
systems
dynamic
which
requires
theory
178
as
a
response
to
this
critique
alemany
oliver
and
vayre
suggest
to
use
abductive
reasoning
as
a
first
step
in
the
research
process
in
order
to
bring
context
to
consumers
digital
traces
and
make
new
theories
emerge
179
additionally
it
has
been
suggested
to
combine
big
data
approaches
with
computer
simulations
such
as
agent
based
models
59
and
complex
systems
agent
based
models
are
increasingly
getting
better
in
predicting
the
outcome
of
social
complexities
of
even
unknown
future
scenarios
through
computer
simulations
that
are
based
on
a
collection
of
mutually
interdependent
algorithms
180
181
finally
the
use
of
multivariate
methods
that
probe
for
the
latent
structure
of
the
data
such
as
factor
analysis
and
cluster
analysis
have
proven
useful
as
analytic
approaches
that
go
well
beyond
the
bi
variate
approaches
cross
tabs
typically
employed
with
smaller
data
sets
in
health
and
biology
conventional
scientific
approaches
are
based
on
experimentation
for
these
approaches
the
limiting
factor
is
the
relevant
data
that
can
confirm
or
refute
the
initial
hypothesis
182
a
new
postulate
is
accepted
now
in
biosciences
the
information
provided
by
the
data
in
huge
volumes
omics
without
prior
hypothesis
is
complementary
and
sometimes
necessary
to
conventional
approaches
based
on
experimentation
183
184
in
the
massive
approaches
it
is
the
formulation
of
a
relevant
hypothesis
to
explain
the
data
that
is
the
limiting
factor
185
the
search
logic
is
reversed
and
the
limits
of
induction
glory
of
science
and
philosophy
scandal
c
d
broad
1926
are
to
be
considered
citation
needed
privacy
advocates
are
concerned
about
the
threat
to
privacy
represented
by
increasing
storage
and
integration
of
personally
identifiable
information
expert
panels
have
released
various
policy
recommendations
to
conform
practice
to
expectations
of
privacy
186
187
188
the
misuse
of
big
data
in
several
cases
by
media
companies
and
even
the
government
has
allowed
for
abolition
of
trust
in
almost
every
fundamental
institution
holding
up
society
189
nayef
al
rodhan
argues
that
a
new
kind
of
social
contract
will
be
needed
to
protect
individual
liberties
in
the
context
of
big
data
and
giant
corporations
that
own
vast
amounts
of
information
and
that
the
use
of
big
data
should
be
monitored
and
better
regulated
at
the
national
and
international
levels
190
barocas
and
nissenbaum
argue
that
one
way
of
protecting
individual
users
is
by
being
informed
about
the
types
of
information
being
collected
with
whom
it
is
shared
under
what
constraints
and
for
what
purposes
191
the
v
model
of
big
data
is
concerning
as
it
centers
around
computational
scalability
and
lacks
in
a
loss
around
the
perceptibility
and
understandability
of
information
this
led
to
the
framework
of
cognitive
big
data
which
characterizes
big
data
applications
according
to
192
large
data
sets
have
been
analyzed
by
computing
machines
for
well
over
a
century
including
the
us
census
analytics
performed
by
ibm
s
punch
card
machines
which
computed
statistics
including
means
and
variances
of
populations
across
the
whole
continent
in
more
recent
decades
science
experiments
such
as
cern
have
produced
data
on
similar
scales
to
current
commercial
big
data
however
science
experiments
have
tended
to
analyze
their
data
using
specialized
custom
built
high
performance
computing
super
computing
clusters
and
grids
rather
than
clouds
of
cheap
commodity
computers
as
in
the
current
commercial
wave
implying
a
difference
in
both
culture
and
technology
stack
ulf
dietrich
reips
and
uwe
matzat
wrote
in
2014
that
big
data
had
become
a
fad
in
scientific
research
157
researcher
danah
boyd
has
raised
concerns
about
the
use
of
big
data
in
science
neglecting
principles
such
as
choosing
a
representative
sample
by
being
too
concerned
about
handling
the
huge
amounts
of
data
193
this
approach
may
lead
to
results
that
have
bias
in
one
way
or
another
194
integration
across
heterogeneous
data
resources
some
that
might
be
considered
big
data
and
others
not
presents
formidable
logistical
as
well
as
analytical
challenges
but
many
researchers
argue
that
such
integrations
are
likely
to
represent
the
most
promising
new
frontiers
in
science
195
in
the
provocative
article
critical
questions
for
big
data
196
the
authors
title
big
data
a
part
of
mythology
large
data
sets
offer
a
higher
form
of
intelligence
and
knowledge
with
the
aura
of
truth
objectivity
and
accuracy
users
of
big
data
are
often
lost
in
the
sheer
volume
of
numbers
and
working
with
big
data
is
still
subjective
and
what
it
quantifies
does
not
necessarily
have
a
closer
claim
on
objective
truth
196
recent
developments
in
bi
domain
such
as
pro
active
reporting
especially
target
improvements
in
usability
of
big
data
through
automated
filtering
of
non
useful
data
and
correlations
197
big
structures
are
full
of
spurious
correlations
198
either
because
of
non
causal
coincidences
law
of
truly
large
numbers
solely
nature
of
big
randomness
199
ramsey
theory
or
existence
of
non
included
factors
so
the
hope
of
early
experimenters
to
make
large
databases
of
numbers
speak
for
themselves
and
revolutionize
scientific
method
is
questioned
200
big
data
analysis
is
often
shallow
compared
to
analysis
of
smaller
data
sets
201
in
many
big
data
projects
there
is
no
large
data
analysis
happening
but
the
challenge
is
the
extract
transform
load
part
of
data
pre
processing
201
big
data
is
a
buzzword
and
a
vague
term
202
203
but
at
the
same
time
an
obsession
203
with
entrepreneurs
consultants
scientists
and
the
media
big
data
showcases
such
as
google
flu
trends
failed
to
deliver
good
predictions
in
recent
years
overstating
the
flu
outbreaks
by
a
factor
of
two
similarly
academy
awards
and
election
predictions
solely
based
on
twitter
were
more
often
off
than
on
target
big
data
often
poses
the
same
challenges
as
small
data
adding
more
data
does
not
solve
problems
of
bias
but
may
emphasize
other
problems
in
particular
data
sources
such
as
twitter
are
not
representative
of
the
overall
population
and
results
drawn
from
such
sources
may
then
lead
to
wrong
conclusions
google
translate
which
is
based
on
big
data
statistical
analysis
of
text
does
a
good
job
at
translating
web
pages
however
results
from
specialized
domains
may
be
dramatically
skewed
on
the
other
hand
big
data
may
also
introduce
new
problems
such
as
the
multiple
comparisons
problem
simultaneously
testing
a
large
set
of
hypotheses
is
likely
to
produce
many
false
results
that
mistakenly
appear
significant
ioannidis
argued
that
most
published
research
findings
are
false
204
due
to
essentially
the
same
effect
when
many
scientific
teams
and
researchers
each
perform
many
experiments
i
e
process
a
big
amount
of
scientific
data
although
not
with
big
data
technology
the
likelihood
of
a
significant
result
being
false
grows
fast
even
more
so
when
only
positive
results
are
published
furthermore
big
data
analytics
results
are
only
as
good
as
the
model
on
which
they
are
predicated
in
an
example
big
data
took
part
in
attempting
to
predict
the
results
of
the
2016
u
s
presidential
election
205
with
varying
degrees
of
success
big
data
has
been
used
in
policing
and
surveillance
by
institutions
like
law
enforcement
and
corporations
206
due
to
the
less
visible
nature
of
data
based
surveillance
as
compared
to
traditional
method
of
policing
objections
to
big
data
policing
are
less
likely
to
arise
according
to
sarah
brayne
s
big
data
surveillance
the
case
of
policing
207
big
data
policing
can
reproduce
existing
societal
inequalities
in
three
ways
if
these
potential
problems
are
not
corrected
or
regulated
the
effects
of
big
data
policing
may
continue
to
shape
societal
hierarchies
conscientious
usage
of
big
data
policing
could
prevent
individual
level
biases
from
becoming
institutional
biases
brayne
also
notes



we
have
lots
of
data
now
what
how
can
we
unlock
real
value
from
our
data
data
science
is
a
multidisciplinary
blend
of
data
inference
algorithmm
development
and
technology
in
order
to
solve
analytically
complex
problems
at
the
core
is
data
troves
of
raw
information
streaming
in
and
stored
in
enterprise
data
warehouses
much
to
learn
by
mining
it
advanced
capabilities
we
can
build
with
it
data
science
is
ultimately
about
using
this
data
in
creative
ways
to
generate
business
value
data
warehouse
discovery
of
data
insight
quantitative
data
analysis
to
help
steer
strategic
business
decisions
development
of
data
product
algorithm
solutions
in
production
operating
at
scale
e
g
recommendation
engines
business
value
this
aspect
of
data
science
is
all
about
uncovering
findings
from
data
diving
in
at
a
granular
level
to
mine
and
understand
complex
behaviors
trends
and
inferences
it
s
about
surfacing
hidden
insight
that
can
help
enable
companies
to
make
smarter
business
decisions
for
example
how
do
data
scientists
mine
out
insights
it
starts
with
data
exploration
when
given
a
challenging
question
data
scientists
become
detectives
they
investigate
leads
and
try
to
understand
pattern
or
characteristics
within
the
data
this
requires
a
big
dose
of
analytical
creativity
then
as
needed
data
scientists
may
apply
quantitative
technique
in
order
to
get
a
level
deeper
e
g
inferential
models
segmentation
analysis
time
series
forecasting
synthetic
control
experiments
etc
the
intent
is
to
scientifically
piece
together
a
forensic
view
of
what
the
data
is
really
saying
this
data
driven
insight
is
central
to
providing
strategic
guidance
in
this
sense
data
scientists
act
as
consultants
guiding
business
stakeholders
on
how
to
act
on
findings
a
data
product
is
a
technical
asset
that
1
utilizes
data
as
input
and
2
processes
that
data
to
return
algorithmically
generated
results
the
classic
example
of
a
data
product
is
a
recommendation
engine
which
ingests
user
data
and
makes
personalized
recommendations
based
on
that
data
here
are
some
examples
of
data
products
this
is
different
from
the
data
insights
section
above
where
the
outcome
to
that
is
to
perhaps
provide
advice
to
an
executive
to
make
a
smarter
business
decision
in
contrast
a
data
product
is
technical
functionality
that
encapsulates
an
algorithm
and
is
designed
to
integrate
directly
into
core
applications
respective
examples
of
applications
that
incorporate
data
product
behind
the
scenes
amazon
s
homepage
gmail
s
inbox
and
autonomous
driving
software
data
scientists
play
a
central
role
in
developing
data
product
this
involves
building
out
algorithms
as
well
as
testing
refinement
and
technical
deployment
into
production
systems
in
this
sense
data
scientists
serve
as
technical
developers
building
assets
that
can
be
leveraged
at
wide
scale
data
science
is
a
blend
of
skills
in
three
major
areas
mathematics
expertise
at
the
heart
of
mining
data
insight
and
building
data
product
is
the
ability
to
view
the
data
through
a
quantitative
lens
there
are
textures
dimensions
and
correlations
in
data
that
can
be
expressed
mathematically
finding
solutions
utilizing
data
becomes
a
brain
teaser
of
heuristics
and
quantitative
technique
solutions
to
many
business
problems
involve
building
analytic
models
grounded
in
the
hard
math
where
being
able
to
understand
the
underlying
mechanics
of
those
models
is
key
to
success
in
building
them
also
a
misconception
is
that
data
science
all
about
statistics
while
statistics
is
important
it
is
not
the
only
type
of
math
utilized
first
there
are
two
branches
of
statistics
classical
statistics
and
bayesian
statistics
when
most
people
refer
to
stats
they
are
generally
referring
to
classical
stats
but
knowledge
of
both
types
is
helpful
furthermore
many
inferential
techniques
and
machine
learning
algorithms
lean
on
knowledge
of
linear
algebra
for
example
a
popular
method
to
discover
hidden
characteristics
in
a
data
set
is
svd
which
is
grounded
in
matrix
math
and
has
much
less
to
do
with
classical
stats
overall
it
is
helpful
for
data
scientists
to
have
breadth
and
depth
in
their
knowledge
of
mathematics
technology
and
hacking
first
let
s
clarify
on
that
we
are
not
talking
about
hacking
as
in
breaking
into
computers
we
re
referring
to
the
tech
programmer
subculture
meaning
of
hacking
i
e
creativity
and
ingenuity
in
using
technical
skills
to
build
things
and
find
clever
solutions
to
problems
why
is
hacking
ability
important
because
data
scientists
utilize
technology
in
order
to
wrangle
enormous
data
sets
and
work
with
complex
algorithms
and
it
requires
tools
far
more
sophisticated
than
excel
data
scientists
need
to
be
able
to
code
prototype
quick
solutions
as
well
as
integrate
with
complex
data
systems
core
languages
associated
with
data
science
include
sql
python
r
and
sas
on
the
periphery
are
java
scala
julia
and
others
but
it
is
not
just
knowing
language
fundamentals
a
hacker
is
a
technical
ninja
able
to
creatively
navigate
their
way
through
technical
challenges
in
order
to
make
their
code
work
along
these
lines
a
data
science
hacker
is
a
solid
algorithmic
thinker
having
the
ability
to
break
down
messy
problems
and
recompose
them
in
ways
that
are
solvable
this
is
critical
because
data
scientists
operate
within
a
lot
of
algorithmic
complexity
they
need
to
have
a
strong
mental
comprehension
of
high
dimensional
data
and
tricky
data
control
flows
full
clarity
on
how
all
the
pieces
come
together
to
form
a
cohesive
solution
strong
business
acumen
it
is
important
for
a
data
scientist
to
be
a
tactical
business
consultant
working
so
closely
with
data
data
scientists
are
positioned
to
learn
from
data
in
ways
no
one
else
can
that
creates
the
responsibility
to
translate
observations
to
shared
knowledge
and
contribute
to
strategy
on
how
to
solve
core
business
problems
this
means
a
core
competency
of
data
science
is
using
data
to
cogently
tell
a
story
no
data
puking
rather
present
a
cohesive
narrative
of
problem
and
solution
using
data
insights
as
supporting
pillars
that
lead
to
guidance
having
this
business
acumen
is
just
as
important
as
having
acumen
for
tech
and
algorithms
there
needs
to
be
clear
alignment
between
data
science
projects
and
business
goals
ultimately
the
value
doesn
t
come
from
data
math
and
tech
itself
it
comes
from
leveraging
all
of
the
above
to
build
valuable
capabilities
and
have
strong
business
influence
the
mindset
a
common
personality
trait
of
data
scientists
is
they
are
deep
thinkers
with
intense
intellectual
curiosity
data
science
is
all
about
being
inquisitive
asking
new
questions
making
new
discoveries
and
learning
new
things
ask
data
scientists
most
obsessed
with
their
work
what
drives
them
in
their
job
and
they
will
not
say
money
the
real
motivator
is
being
able
to
use
their
creativity
and
ingenuity
to
solve
hard
problems
and
constantly
indulge
in
their
curiosity
deriving
complex
reads
from
data
is
beyond
just
making
an
observation
it
is
about
uncovering
truth
that
lies
hidden
beneath
the
surface
problem
solving
is
not
a
task
but
an
intellectually
stimulating
journey
to
a
solution
data
scientists
are
passionate
about
what
they
do
and
reap
great
satisfaction
in
taking
on
challenge
training
there
is
a
glaring
misconception
out
there
that
you
need
a
sciences
or
math
ph
d
to
become
a
legitimate
data
scientist
that
view
misses
the
point
that
data
science
is
multidisciplinary
highly
focused
study
in
academia
is
certainly
helpful
but
doesn
t
guarantee
that
graduates
have
the
full
set
of
experiences
and
abilities
to
succeed
e
g
a
ph
d
statistician
may
still
need
to
pick
up
a
lot
of
programming
skills
and
gain
business
experience
to
complete
the
trifecta
in
fact
data
science
is
such
a
relatively
new
and
rising
discipline
that
universities
have
not
caught
up
in
developing
comprehensive
data
science
degree
programs
meaning
that
no
one
can
really
claim
to
have
done
all
the
schooling
to
be
become
a
data
scientist
where
does
much
of
the
training
come
from
the
unyielding
intellectual
curiosity
of
data
scientists
push
them
to
be
motivated
autodidacts
driven
to
self
learn
the
right
skills
guided
by
their
own
determination
there
are
a
slew
of
terms
closely
related
to
data
science
that
we
hope
to
add
some
clarity
around
analytics
has
risen
quickly
in
popular
business
lingo
over
the
past
several
years
the
term
is
used
loosely
but
generally
meant
to
describe
critical
thinking
that
is
quantitative
in
nature
technically
analytics
is
the
science
of
analysis
put
another
way
the
practice
of
analyzing
information
to
make
decisions
is
analytics
the
same
thing
as
data
science
depends
on
context
sometimes
it
is
synonymous
with
the
definition
of
data
science
that
we
have
described
and
sometimes
it
represents
something
else
a
data
scientist
using
raw
data
to
build
a
predictive
algorithm
falls
into
the
scope
of
analytics
at
the
same
time
a
non
technical
business
user
interpreting
pre
built
dashboard
reports
e
g
ga
is
also
in
the
realm
of
analytics
but
does
not
cross
into
the
skill
set
needed
in
data
science
analytics
has
come
to
have
fairly
broad
meaning
at
the
end
of
the
day
as
long
as
you
understand
beyond
the
buzzword
level
the
exact
semantics
don
t
matter
much
analyst
is
somewhat
of
an
ambiguous
job
title
that
can
represent
many
different
types
of
roles
data
analyst
marketing
analyst
operations
analyst
financial
analyst
etc
what
does
this
mean
in
comparison
to
data
scientist
thus
analyst
and
data
scientist
is
not
exactly
synonymous
but
also
not
mutually
exclusive
here
is
our
interpretation
of
how
these
job
titles
map
to
skills
and
scope
of
responsibilities
machine
learning
is
a
term
closely
associated
with
data
science
it
refers
to
a
broad
class
of
methods
that
revolve
around
data
modeling
to
1
algorithmically
make
predictions
and
2
algorithmically
decipher
patterns
in
data
not
all
machine
learning
methods
fit
neatly
into
the
above
two
categories
for
example
collaborative
filtering
is
a
type
of
recommendations
algorithm
with
elements
related
to
both
supervised
and
unsupervised
learning
contextual
bandits
are
a
twist
on
supervised
learning
where
predictions
get
adaptively
modified
on
the
fly
using
live
feedback
this
wide
ranging
breadth
of
machine
learning
techniques
comprise
an
important
part
of
the
data
science
toolbox
it
is
up
to
the
data
scientist
to
figure
out
which
tool
to
use
in
different
circumstances
as
well
as
how
to
use
the
tool
correctly
in
order
to
solve
analytically
open
ended
problems
raw
data
can
be
unstructured
and
messy
with
information
coming
from
disparate
data
sources
mismatched
or
missing
records
and
a
slew
of
other
tricky
issues
data
munging
is
a
term
to
describe
the
data
wrangling
to
bring
together
data
into
cohesive
views
as
well
as
the
janitorial
work
of
cleaning
up
data
so
that
it
is
polished
and
ready
for
downstream
usage
this
requires
good
pattern
recognition
sense
and
clever
hacking
skills
to
merge
and
transform
masses
of
database
level
information
if
not
properly
done
dirty
data
can
obfuscate
the
truth
hidden
in
the
data
set
and
completely
mislead
results
thus
any
data
scientist
must
be
skillful
and
nimble
at
data
munging
in
order
to
have
accurate
usable
data
before
applying
more
sophisticated
analytical
tactics
for
any
company
that
wishes
to
enhance
their
business
by
being
more
data
driven
data
science
is
the
secret
sauce
data
science
projects
can
have
multiplicative
returns
on
investment
both
from
guidance
through
data
insight
and
development
of
data
product
though
hiring
people
who
carry
this
potent
mix
of
different
skills
is
easier
said
than
done
there
is
simply
not
enough
supply
of
data
scientists
in
the
market
to
meet
the
demand
data
scientist
salary
is
sky
high
thus
when
you
manage
to
hire
data
scientists
nurture
them
keep
them
engaged
give
them
autonomy
to
be
their
own
architects
in
how
to
solve
problems
this
sets
them
up
in
the
company
to
be
highly
motivated
problem
solvers
there
to
tackle
the
toughest
analytical
challenges
for
big
data
specialists
only
currently
in
very
high
demand



sungkyunkwan
university
skku
or
simply
seongdae
hangeul
성균관대학교
hanja
成均館大學校
is
a
private
comprehensive
research
university
in
south
korea
the
institution
traces
its
origins
to
the
historic
sungkyunkwan
founded
in
1398
and
located
in
central
seoul
4
as
the
foremost
educational
institution
of
the
joseon
dynasty
it
was
governed
by
the
great
code
of
the
state
administration
5
with
royal
assent
6
it
was
restructured
as
a
comprehensive
university
in
the
late
19th
century
and
has
since
greatly
expanded
its
course
offerings
it
is
widely
regarded
as
one
of
the
most
prestigious
private
universities
in
south
korea
notable
for
its
numerous
influential
alumni
strong
research
output
and
close
partnership
with
samsung
the
university
spends
heavily
on
research
and
development
mostly
sponsored
by
samsung
hyundai
and
government
agencies
producing
high
end
research
scientists
including
chemical
engineering
professor
park
nam
gyu
who
was
nominated
for
the
nobel
prize
in
chemistry
in
2017
by
clarivate
analytics
7
and
physics
professor
lee
young
hee
director
of
the
center
for
integrated
nanostructure
physics
in
the
institute
for
basic
science
both
scientists
frequently
appear
in
nature
8
the
university
s
humanities
and
social
sciences
campus
also
housing
arts
departments
is
in
central
seoul
on
the
same
hill
as
changdeokgung
and
changgyeonggung
two
of
the
royal
palaces
of
joseon
it
is
near
hyehwa
dong
and
daehangno
the
nearest
subway
station
is
hyehwa
station
on
seoul
subway
line
4
the
natural
sciences
campus
housing
natural
science
engineering
medicine
and
sports
departments
is
within
walking
distance
of
sungkyunkwan
university
station
in
the
northwest
of
suwon
the
101
hectare
campus
45
km
south
of
seoul
was
established
in
1978
sungkyunkwan
was
established
in
1398
as
the
joseon
dynasty
s
highest
educational
institution
its
name
means
sung
成
to
make
kyun
均
harmonious
society
kwan
館
institute
it
focused
on
in
depth
study
of
the
chinese
classics
confucian
canon
and
literature
of
the
era
and
how
to
apply
the
knowledge
to
governing
the
nation
and
understanding
the
nature
of
humanity
it
also
served
as
a
shrine
see
munmyo
to
the
confucian
sages
where
rituals
were
held
regularly
to
honor
them
and
their
teachings
it
was
located
within
the
city
walls
of
the
capital
during
the
joseon
period
hanseong
or
modern
day
seoul
it
followed
the
example
of
the
goryeo
period
gukjagam
which
in
its
latter
years
was
also
known
by
the
name
sungkyunkwan
numerous
korean
historical
figures
including
yi
hwang
and
yi
i
studied
at
and
graduated
from
sungkyunkwan
a
considerable
amount
of
korean
literature
and
works
of
hanja
calligraphy
were
created
and
archived
by
sungkyunkwan
scholars
over
the
centuries
during
the
period
of
japanese
rule
in
the
first
half
of
the
twentieth
century
sungkyunkwan
was
downgraded
and
almost
closed
by
the
governor
general
of
korea
in
favor
of
the
imperial
university
at
the
end
of
world
war
ii
however
it
was
officially
reopened
as
a
college
by
the
united
states
army
military
government
in
korea
before
long
it
was
reinstated
by
the
ex
rector
of
sungkyunkwan
kim
changsook
after
the
korean
war
as
the
nation
modernized
and
underwent
social
political
and
economic
reforms
skku
played
an
important
role
in
academic
freedom
in
higher
education
and
also
kept
traditional
ethics
and
morality
alive
in
korean
society
samsung
partnered
with
skku
in
the
period
of
1965
1977
and
renewed
the
partnership
in
1996
the
partnership
has
helped
skku
realize
its
vision
in
pursuit
of
globalization
and
fostering
talented
graduates
10
through
the
partnership
skku
has
developed
high
quality
research
infrastructure
and
achieved
excellent
human
resource
management
the
partnership
also
enabled
skku
to
develop
world
leading
academic
programs
in
software
development
mobile
communications
engineering
energy
engineering
nanotechnology
business
medicine
and
law
11
through
the
samsung
global
scholarship
program
gsp
each
year
15
25
students
are
selected
for
seoul
national
university
s
engineering
program
or
skku
s
graduate
school
of
business
skk
gsb
selected
gsp
students
currently
study
for
three
semesters
previously
it
was
four
semesters
including
a
possibility
of
spending
a
semester
at
one
of
skk
gsb
s
top
partner
universities
in
the
u
s
mit
sloan
columbia
university
northwestern
university
s
kellogg
school
of
management
university
of
michigan
s
ross
school
of
business
dartmouth
college
s
tuck
school
of
business
or
indiana
university
s
kelley
school
of
business
according
to
the
ranking
of
south
korean
universities
annually
published
by
national
daily
newspaper
joongang
daily
sungkyunkwan
university
is
ranked
nationally
as
the
3rd
best
university
in
south
korea
after
snu
and
kaist
22
it
is
the
number
one
private
comprehensive
research
university
in
south
korea
according
to
u
s
news
world
report
internationally
skku
is
ranked
95th
in
the
quacquarelli
symonds
qs
world
university
rankings
2020
23
in
the
times
higher
education
2021
world
university
rankings
skku
is
ranked
101st
24
in
the
qs
asia
rankings
skku
is
ranked
15th
25
the
reputation
of
the
university
stems
from
skku
s
international
engagement
including
short
term
study
abroad
programs
and
dual
degree
programs
as
well
as
its
industrial
partnerships
and
its
graduate
reputation
as
evidenced
in
the
high
employment
rate
of
skku
graduates
in
the
financial
times
skk
gsb
s
mba
is
ranked
35th
worldwide
7th
in
asia
and
1st
in
korea
26
skku
s
school
of
medicine
is
affiliated
with
samsung
medical
center
the
top
research
hospital
in
korea
skku
s
motto
humanity
righteousness
propriety
and
wisdom
仁
義
禮
智
reflects
the
basic
spirit
of
confucianism
these
four
cardinal
virtues
express
humankind
s
four
inherent
elements
of
spirit
action
conscience
and
intellect
humanity
abides
in
the
heart
that
loves
righteousness
abides
in
the
heart
that
knows
right
from
wrong
propriety
abides
in
the
heart
that
knows
forbearance
and
wisdom
abides
in
the
heart
that
perceives
confucian
philosophy
attests
to
man
s
innate
goodness
and
at
the
same
time
recognizes
that
this
quality
must
nevertheless
be
awakened
and
nurtured
these
four
principles
which
comprise
skku
s
educational
philosophy
are
the
basis
for
higher
education
s
goals
of
the
search
for
truth
and
the
establishment
of
social
justice
which
are
in
turn
based
on
humanity
5
the
university
s
symbol
the
ginkgo
leaf
is
derived
from
the
giant
ginkgo
trees
natural
monument
no
59
at
myeongnyundang
both
trees
are
male
and
thus
do
not
bear
fruit
they
are
believed
to
have
been
planted
in
1519
by
yun
tak
a
former
president
of
sungkyunkwan
the
library
is
equipped
with
state
of
the
art
digital
media
room
where
students
can
have
recreational
activity
like
watching
movies
the
library
also
offers
several
cd
player
stations
for
amusements
open
cafe
sleeping
arena
where
students
can
take
nap
if
tired
27
skku
learning
factory
is
a
student
facility
at
natural
sciences
campus
in
suwon
where
creative
ideas
can
be
made
into
a
prototype
product
using
3d
printers
laser
cutters
cnc
router
and
arduino
it
has
been
established
by
the
fusion
based
creative
informatics
human
resources
development
team
and
it
serves
as
a
place
where
students
can
realize
their
ideas
and
build
human
connections
sungkyunkwan
university
offers
on
campus
dormitories
to
its
students
in
the
campuses
which
are
known
as
skku
dorms
humanities
and
social
sciences
campus
at
seoul
offers
ten
dormitories
and
housing
facilities
namely
e
house
g
house
k
house
c
house
i
house
m
house
crownville
a
crownville
c
victory
house
and
lwg
house
whereas
natural
sciences
campus
at
suwon
offers
five
dormitories
namely
in
gwan
ui
gwan
ye
gwan
shin
gwan
ji
gwan
28
dorm
culture
of
the
university
is
vibrant
owing
to
frequent
recreational
events
such
as
free
pizza
party
outdoor
trip
painting
competition
yoga
class
and
so
on
targeting
its
international
students
the
dorm
entrances
are
secured
with
automatic
rfid
key
tag
doors
which
ensure
only
the
students
can
have
legal
entry
inside
routine
fire
safety
and
earth
quake
safety
simulations
in
the
dorms
are
performed
every
semester
to
ensure
safety
of
the
students
the
dormitories
house
both
male
and
female
students
but
floors
are
designated
for
a
specific
gender
28
skku
dorms
provide
variety
of
room
types
depending
on
the
need
fee
and
academic
results
students
can
be
offered
single
two
four
persons
rooms
apartment
type
facilities
are
also
offered
where
more
than
four
students
live
in
separate
rooms
in
apartment
all
the
rooms
are
equipped
with
furniture
air
conditioner
and
free
wifi
special
single
rooms
are
reserved
for
disabled
students
in
shin
gwan
dorm
each
dormitories
are
equipped
with
cctv
and
free
wifi
vending
machines
printers
and
atm
machines
are
available
at
the
entrance
of
every
dorm
reading
rooms
and
common
rooms
at
each
floor
with
television
and
microwave
oven
are
available
laundry
rooms
are
equipped
with
washing
machines
cloth
dryer
and
electric
iron
which
are
free
of
cost
some
of
the
dormitories
like
e
house
shin
gwan
and
in
gwan
have
in
house
gym
having
a
significantly
large
international
student
community
skku
dorms
offer
kitchen
facilities
for
all
of
its
students
all
kitchens
have
numbered
cabinets
allocated
to
a
particular
student
for
a
semester
sungkyunkwan
advanced
institute
of
nanotechnology
saint
was
founded
on
1
march
2005
as
one
of
the
four
core
programs
of
sungkyunkwan
university
s
vision2010
plan
to
be
ranked
in
the
top
100
universities
in
the
world
with
financial
support
from
samsung
advanced
institute
of
technology
sait
its
goal
is
to
become
one
of
the
world
s
top
5
nanotechnology
related
institutes
the
current
director
of
saint
is
michael
grätzel
n
center
is
the
home
of
the
center
for
integrated
nanostructure
physics
in
the
institute
for
basic
science
and
the
center
for
neuroscience
imaging
research
cnir
29
professor
lee
young
hee
an
internationally
renowned
physicist
engaged
in
nanotechnology
research
8
is
the
director
sungkyun
language
institute
sli
is
a
semi
autonomous
division
of
sungkyunkwan
university
teaching
japanese
mandarin
and
korean
though
mandarin
is
not
taught
at
the
suwon
campus
korean
is
taught
at
six
levels
from
beginner
to
advanced
the
two
japanese
lecturers
based
in
suwon
are
korean
there
are
several
foreign
lecturers
of
other
languages
in
seoul
and
korean
lecturers
of
english
on
both
campuses
the
university
college
is
chiefly
responsible
for
first
year
undergraduates
outside
the
english
department
english
courses
are
chiefly
in
academic
writing
academic
presentation
and
debate
there
are
also
several
specialized
courses
including
business
english
english
for
scientific
purposes
english
literature
global
englishes
entrepreneurship
english
careers
english
news
and
media
literacy
and
sports
english
sungkyunkwan
university
has
a
high
number
of
international
students
making
up
over
10
of
the
total
undergraduate
student
body
in
2011
the
population
of
international
students
at
skku
surpassed
1
000
30
there
were
over
2
700
international
students
enrolled
at
skku
in
2013
and
each
year
more
than
2
000
korean
students
from
skku
go
abroad
skku
maintains
partnerships
with
over
653
universities
in
over
73
countries
around
the
world
and
has
agreements
with
21
overseas
institutions
to
offer
dual
degree
programs
31
a
majority
of
skku
s
international
students
attend
the
international
summer
semester
iss
program
usually
held
from
late
june
to
late
july
started
in
2008
it
has
grown
to
over
1
500
students
from
over
65
universities
in
over
25
countries
skku
s
winter
international
student
experience
wise
is
newer
than
its
iss
program
it
started
in
2015
and
occurs
ever
january
for
just
under
four
weeks
it
is
a
bit
smaller
than
the
iss
with
around
200
students
from
26
universities
and
16
nations
each
year
and
growing
it
is
offered
especially
for
students
from
warmer
regions
including
southeast
asia
south
america
and
australia
to
experience
winter
life
in
korea
the
graduate
school
of
business
gsb
was
established
in
2004
with
the
launching
of
the
global
mba
program
32
the
global
mba
program
was
the
nation
s
first
mba
program
to
be
fully
taught
in
english
and
was
set
up
in
collaboration
with
mit
s
sloan
school
of
management
and
indiana
university
s
kelley
school
of
business
both
in
the
united
states
the
skk
gsb
global
mba
has
also
been
ranked
by
the
financial
times
as
the
1
mba
in
korea
top
11
in
asia
and
59th
worldwide
26
in
addition
to
the
mba
program
other
subspecialized
master
s
degree
programs
and
dual
masters
programs
are
also
offered
its
partner
institutions
include
the
sloan
school
of
management
the
kelley
school
of
business
and
uc
berkeley
s
haas
school
of
business
in
the
united
states
and
the
edhec
business
school
in
france
33
34
mgb
program
skku
is
also
offering
a
program
called
the
master
of
global
business
this
program
is
in
partnership
with
the
university
of
victoria
canada
and
montpellier
business
school
france
in
february
skuu
is
welcoming
35
students
from
13
different
countries
the
module
mostly
focuses
on
consulting
projects
with
famous
korean
companies
such
as
lg
cj
kb
bank
etc
35
sungkyunkwan
university
s
department
of
english
language
and
literature
is
the
birthplace
and
home
of
the
korean
affiliate
of
the
association
for
the
study
of
literature
and
environment
asle
korea
or
asle
k
asle
korea
6
hosts
two
conferences
a
year
spring
and
fall
and
publishes
literature
and
environment
문학과환경
a
journal
dedicated
to
extending
ecocritical
scholarship
with
articles
written
primarily
in
korean
and
english
the
old
campus
of
sungkyunkwan
was
the
setting
for
the
fusion
historical
drama
sungkyunkwan
scandal
which
also
starred
alumnus
song
joong
ki
about
a
student
who
disguises
herself
as
a
male
to
attend
the
boys
only
confucian
academy
the
setting
resulted
in
increased
interest
in
skku
from
international
audiences
who
watched
the
drama
skku
is
the
founding
place
and
was
the
primary
practice
venue
of
korean
national
cricket
team
36
current
library
holdings
1
830
806
bound
volumes
university
area
3
593
341
m2
building
area
344
510
m2
under
the
college
of
sports
science
several
student
sports
clubs
at
sungkyunkwan
university
are
active
including
baseball
club
floor
ball
club
tennis
club
basketball
club
soccer
club
volleyball
club
and
cricket
club
full
size
soccer
field
basketball
playground
and
baseball
fields
are
located
inside
the
campus
baseball
field
at
sungkyunkwan
university
basketball
field
soccer
field
volleyball
playground
coordinates
37
35
14
n
126
59
39
e
37
58722
n
126
99417
e
37
58722
126
99417



the
story
of
how
data
scientists
became
sexy
is
mostly
the
story
of
the
coupling
of
the
mature
discipline
of
statistics
with
a
very
young
one
computer
science
the
term
data
science
has
emerged
only
recently
to
specifically
designate
a
new
profession
that
is
expected
to
make
sense
of
the
vast
stores
of
big
data
but
making
sense
of
data
has
a
long
history
and
has
been
discussed
by
scientists
statisticians
librarians
computer
scientists
and
others
for
years
the
following
timeline
traces
the
evolution
of
the
term
data
science
and
its
use
attempts
to
define
it
and
related
terms
1962
john
w
tukey
writes
in
the
future
of
data
analysis
for
a
long
time
i
thought
i
was
a
statistician
interested
in
inferences
from
the
particular
to
the
general
but
as
i
have
watched
mathematical
statistics
evolve
i
have
had
cause
to
wonder
and
doubt
i
have
come
to
feel
that
my
central
interest
is
in
data
analysis
data
analysis
and
the
parts
of
statistics
which
adhere
to
it
must
take
on
the
characteristics
of
science
rather
than
those
of
mathematics
data
analysis
is
intrinsically
an
empirical
science
how
vital
and
how
important
is
the
rise
of
the
stored
program
electronic
computer
in
many
instances
the
answer
may
surprise
many
by
being
important
but
not
vital
although
in
others
there
is
no
doubt
but
what
the
computer
has
been
vital
in
1947
tukey
coined
the
term
bit
which
claude
shannon
used
in
his
1948
paper
a
mathematical
theory
of
communications
in
1977
tukey
published
exploratory
data
analysis
arguing
that
more
emphasis
needed
to
be
placed
on
using
data
to
suggest
hypotheses
to
test
and
that
exploratory
data
analysis
and
confirmatory
data
analysis
can
and
should
proceed
side
by
side
1974
peter
naur
publishes
concise
survey
of
computer
methods
in
sweden
and
the
united
states
the
book
is
a
survey
of
contemporary
data
processing
methods
that
are
used
in
a
wide
range
of
applications
it
is
organized
around
the
concept
of
data
as
defined
in
the
ifip
guide
to
concepts
and
terms
in
data
processing
data
is
a
representation
of
facts
or
ideas
in
a
formalized
manner
capable
of
being
communicated
or
manipulated
by
some
process
the
preface
to
the
book
tells
the
reader
that
a
course
plan
was
presented
at
the
ifip
congress
in
1968
titled
datalogy
the
science
of
data
and
of
data
processes
and
its
place
in
education
and
that
in
the
text
of
the
book
the
term
data
science
has
been
used
freely
naur
offers
the
following
definition
of
data
science
the
science
of
dealing
with
data
once
they
have
been
established
while
the
relation
of
the
data
to
what
they
represent
is
delegated
to
other
fields
and
sciences
1977
the
international
association
for
statistical
computing
iasc
is
established
as
a
section
of
the
isi
it
is
the
mission
of
the
iasc
to
link
traditional
statistical
methodology
modern
computer
technology
and
the
knowledge
of
domain
experts
in
order
to
convert
data
into
information
and
knowledge
1989
gregory
piatetsky
shapiro
organizes
and
chairs
the
first
knowledge
discovery
in
databases
kdd
workshop
in
1995
it
became
the
annual
acm
sigkdd
conference
on
knowledge
discovery
and
data
mining
kdd
september
1994
businessweek
publishes
a
cover
story
on
database
marketing
companies
are
collecting
mountains
of
information
about
you
crunching
it
to
predict
how
likely
you
are
to
buy
a
product
and
using
that
knowledge
to
craft
a
marketing
message
precisely
calibrated
to
get
you
to
do
so
an
earlier
flush
of
enthusiasm
prompted
by
the
spread
of
checkout
scanners
in
the
1980s
ended
in
widespread
disappointment
many
companies
were
too
overwhelmed
by
the
sheer
quantity
of
data
to
do
anything
useful
with
the
information
still
many
companies
believe
they
have
no
choice
but
to
brave
the
database
marketing
frontier
1996
members
of
the
international
federation
of
classification
societies
ifcs
meet
in
kobe
japan
for
their
biennial
conference
for
the
first
time
the
term
data
science
is
included
in
the
title
of
the
conference
data
science
classification
and
related
methods
the
ifcs
was
founded
in
1985
by
six
country
and
language
specific
classification
societies
one
of
which
the
classification
society
was
founded
in
1964
the
classification
societies
have
variously
used
the
terms
data
analysis
data
mining
and
data
science
in
their
publications
1996
usama
fayyad
gregory
piatetsky
shapiro
and
padhraic
smyth
publish
from
data
mining
to
knowledge
discovery
in
databases
they
write
historically
the
notion
of
finding
useful
patterns
in
data
has
been
given
a
variety
of
names
including
data
mining
knowledge
extraction
information
discovery
information
harvesting
data
archeology
and
data
pattern
processing
in
our
view
kdd
knowledge
discovery
in
databases
refers
to
the
overall
process
of
discovering
useful
knowledge
from
data
and
data
mining
refers
to
a
particular
step
in
this
process
data
mining
is
the
application
of
specific
algorithms
for
extracting
patterns
from
data
the
additional
steps
in
the
kdd
process
such
as
data
preparation
data
selection
data
cleaning
incorporation
of
appropriate
prior
knowledge
and
proper
interpretation
of
the
results
of
mining
are
essential
to
ensure
that
useful
knowledge
is
derived
from
the
data
blind
application
of
data
mining
methods
rightly
criticized
as
data
dredging
in
the
statistical
literature
can
be
a
dangerous
activity
easily
leading
to
the
discovery
of
meaningless
and
invalid
patterns
1997
in
his
inaugural
lecture
for
the
h
c
carver
chair
in
statistics
at
the
university
of
michigan
professor
c
f
jeff
wu
currently
at
the
georgia
institute
of
technology
calls
for
statistics
to
be
renamed
data
science
and
statisticians
to
be
renamed
data
scientists
1997
the
journal
data
mining
and
knowledge
discovery
is
launched
the
reversal
of
the
order
of
the
two
terms
in
its
title
reflecting
the
ascendance
of
data
mining
as
the
more
popular
way
to
designate
extracting
information
from
large
databases
december
1999
jacob
zahavi
is
quoted
in
mining
data
for
nuggets
of
knowledge
in
knowledge
wharton
conventional
statistical
methods
work
well
with
small
data
sets
today
s
databases
however
can
involve
millions
of
rows
and
scores
of
columns
of
data
scalability
is
a
huge
issue
in
data
mining
another
technical
challenge
is
developing
models
that
can
do
a
better
job
analyzing
data
detecting
non
linear
relationships
and
interaction
between
elements
special
data
mining
tools
may
have
to
be
developed
to
address
web
site
decisions
2001
william
s
cleveland
publishes
data
science
an
action
plan
for
expanding
the
technical
areas
of
the
field
of
statistics
it
is
a
plan
to
enlarge
the
major
areas
of
technical
work
of
the
field
of
statistics
because
the
plan
is
ambitious
and
implies
substantial
change
the
altered
field
will
be
called
data
science
cleveland
puts
the
proposed
new
discipline
in
the
context
of
computer
science
and
the
contemporary
work
in
data
mining
the
benefit
to
the
data
analyst
has
been
limited
because
the
knowledge
among
computer
scientists
about
how
to
think
of
and
approach
the
analysis
of
data
is
limited
just
as
the
knowledge
of
computing
environments
by
statisticians
is
limited
a
merger
of
knowledge
bases
would
produce
a
powerful
force
for
innovation
this
suggests
that
statisticians
should
look
to
computing
for
knowledge
today
just
as
data
science
looked
to
mathematics
in
the
past
departments
of
data
science
should
contain
faculty
members
who
devote
their
careers
to
advances
in
computing
with
data
and
who
form
partnership
with
computer
scientists
2001
leo
breiman
publishes
statistical
modeling
the
two
cultures
pdf
there
are
two
cultures
in
the
use
of
statistical
modeling
to
reach
conclusions
from
data
one
assumes
that
the
data
are
generated
by
a
given
stochastic
data
model
the
other
uses
algorithmic
models
and
treats
the
data
mechanism
as
unknown
the
statistical
community
has
been
committed
to
the
almost
exclusive
use
of
data
models
this
commitment
has
led
to
irrelevant
theory
questionable
conclusions
and
has
kept
statisticians
from
working
on
a
large
range
of
interesting
current
problems
algorithmic
modeling
both
in
theory
and
practice
has
developed
rapidly
in
fields
outside
statistics
it
can
be
used
both
on
large
complex
data
sets
and
as
a
more
accurate
and
informative
alternative
to
data
modeling
on
smaller
data
sets
if
our
goal
as
a
field
is
to
use
data
to
solve
problems
then
we
need
to
move
away
from
exclusive
dependence
on
data
models
and
adopt
a
more
diverse
set
of
tools
april
2002
launch
of
data
science
journal
publishing
papers
on
the
management
of
data
and
databases
in
science
and
technology
the
scope
of
the
journal
includes
descriptions
of
data
systems
their
publication
on
the
internet
applications
and
legal
issues
the
journal
is
published
by
the
committee
on
data
for
science
and
technology
codata
of
the
international
council
for
science
icsu
january
2003
launch
of
journal
of
data
science
by
data
science
we
mean
almost
everything
that
has
something
to
do
with
data
collecting
analyzing
modeling
yet
the
most
important
part
is
its
applications
all
sorts
of
applications
this
journal
is
devoted
to
applications
of
statistical
methods
at
large
the
journal
of
data
science
will
provide
a
platform
for
all
data
workers
to
present
their
views
and
exchange
ideas
may
2005
thomas
h
davenport
don
cohen
and
al
jacobson
publish
competing
on
analytics
a
babson
college
working
knowledge
research
center
report
describing
the
emergence
of
a
new
form
of
competition
based
on
the
extensive
use
of
analytics
data
and
fact
based
decision
making
instead
of
competing
on
traditional
factors
companies
are
beginning
to
employ
statistical
and
quantitative
analysis
and
predictive
modeling
as
primary
elements
of
competition
the
research
is
later
published
by
davenport
in
the
harvard
business
review
january
2006
and
is
expanded
with
jeanne
g
harris
into
the
book
competing
on
analytics
the
new
science
of
winning
march
2007
september
2005
the
national
science
board
publishes
long
lived
digital
data
collections
enabling
research
and
education
in
the
21st
century
one
of
the
recommendations
of
the
report
reads
the
nsf
working
in
partnership
with
collection
managers
and
the
community
at
large
should
act
to
develop
and
mature
the
career
path
for
data
scientists
and
to
ensure
that
the
research
enterprise
includes
a
sufficient
number
of
high
quality
data
scientists
the
report
defines
data
scientists
as
the
information
and
computer
scientists
database
and
software
engineers
and
programmers
disciplinary
experts
curators
and
expert
annotators
librarians
archivists
and
others
who
are
crucial
to
the
successful
management
of
a
digital
data
collection
2007
the
research
center
for
dataology
and
data
science
is
established
at
fudan
university
shanghai
china
in
2009
two
of
the
center
s
researchers
yangyong
zhu
and
yun
xiong
publish
introduction
to
dataology
and
data
science
in
which
they
state
different
from
natural
science
and
social
science
dataology
and
data
science
takes
data
in
cyberspace
as
its
research
object
it
is
a
new
science
the
center
holds
annual
symposiums
on
dataology
and
data
science
july
2008
the
jisc
publishes
the
final
report
of
a
study
it
commissioned
to
examine
and
make
recommendations
on
the
role
and
career
development
of
data
scientists
and
the
associated
supply
of
specialist
data
curation
skills
to
the
research
community
the
study
s
final
report
the
skills
role
career
structure
of
data
scientists
curators
assessment
of
current
practice
future
needs
defines
data
scientists
as
people
who
work
where
the
research
is
carried
out
or
in
the
case
of
data
centre
personnel
in
close
collaboration
with
the
creators
of
the
data
and
may
be
involved
in
creative
enquiry
and
analysis
enabling
others
to
work
with
digital
data
and
developments
in
data
base
technology
january
2009
harnessing
the
power
of
digital
data
for
science
and
society
is
published
this
report
of
the
interagency
working
group
on
digital
data
to
the
committee
on
science
of
the
national
science
and
technology
council
states
that
the
nation
needs
to
identify
and
promote
the
emergence
of
new
disciplines
and
specialists
expert
in
addressing
the
complex
and
dynamic
challenges
of
digital
preservation
sustained
access
reuse
and
repurposing
of
data
many
disciplines
are
seeing
the
emergence
of
a
new
type
of
data
science
and
management
expert
accomplished
in
the
computer
information
and
data
sciences
arenas
and
in
another
domain
science
these
individuals
are
key
to
the
current
and
future
success
of
the
scientific
enterprise
however
these
individuals
often
receive
little
recognition
for
their
contributions
and
have
limited
career
paths
january
2009
hal
varian
google
s
chief
economist
tells
the
mckinsey
quarterly
i
keep
saying
the
sexy
job
in
the
next
ten
years
will
be
statisticians
people
think
i
m
joking
but
who
would
ve
guessed
that
computer
engineers
would
ve
been
the
sexy
job
of
the
1990s
the
ability
to
take
data
to
be
able
to
understand
it
to
process
it
to
extract
value
from
it
to
visualize
it
to
communicate
it
that
s
going
to
be
a
hugely
important
skill
in
the
next
decades
because
now
we
really
do
have
essentially
free
and
ubiquitous
data
so
the
complimentary
scarce
factor
is
the
ability
to
understand
that
data
and
extract
value
from
it
i
do
think
those
skills
of
being
able
to
access
understand
and
communicate
the
insights
you
get
from
data
analysis
are
going
to
be
extremely
important
managers
need
to
be
able
to
access
and
understand
the
data
themselves
march
2009
kirk
d
borne
and
other
astrophysicists
submit
to
the
astro2010
decadal
survey
a
paper
titled
the
revolution
in
astronomy
education
data
science
for
the
masses
pdf
training
the
next
generation
in
the
fine
art
of
deriving
intelligent
understanding
from
data
is
needed
for
the
success
of
sciences
communities
projects
agencies
businesses
and
economies
this
is
true
for
both
specialists
scientists
and
non
specialists
everyone
else
the
public
educators
and
students
workforce
specialists
must
learn
and
apply
new
data
science
research
techniques
in
order
to
advance
our
understanding
of
the
universe
non
specialists
require
information
literacy
skills
as
productive
members
of
the
21st
century
workforce
integrating
foundational
skills
for
lifelong
learning
in
a
world
increasingly
dominated
by
data
may
2009
mike
driscoll
writes
in
the
three
sexy
skills
of
data
geeks
with
the
age
of
data
upon
us
those
who
can
model
munge
and
visually
communicate
data
call
us
statisticians
or
data
geeks
are
a
hot
commodity
driscoll
will
follow
up
with
the
seven
secrets
of
successful
data
scientists
in
august
2010
june
2009
nathan
yau
writes
in
rise
of
the
data
scientist
as
we
ve
all
read
by
now
google
s
chief
economist
hal
varian
commented
in
january
that
the
next
sexy
job
in
the
next
10
years
would
be
statisticians
obviously
i
whole
heartedly
agree
heck
i
d
go
a
step
further
and
say
they
re
sexy
now
mentally
and
physically
however
if
you
went
on
to
read
the
rest
of
varian
s
interview
you
d
know
that
by
statisticians
he
actually
meant
it
as
a
general
title
for
someone
who
is
able
to
extract
information
from
large
datasets
and
then
present
something
of
use
to
non
data
experts
ben
fry
argues
for
an
entirely
new
field
that
combines
the
skills
and
talents
from
often
disjoint
areas
of
expertise
computer
science
mathematics
statistics
and
data
mining
graphic
design
infovis
and
human
computer
interaction
and
after
two
years
of
highlighting
visualization
on
flowingdata
it
seems
collaborations
between
the
fields
are
growing
more
common
but
more
importantly
computational
information
design
edges
closer
to
reality
we
re
seeing
data
scientists
people
who
can
do
it
all
emerge
from
the
rest
of
the
pack
june
2009
troy
sadkowsky
creates
the
data
scientists
group
on
linkedin
as
a
companion
to
his
website
datasceintists
com
which
later
became
datascientists
net
february
2010
kenneth
cukier
writes
in
the
economist
special
report
data
data
everywhere
a
new
kind
of
professional
has
emerged
the
data
scientist
who
combines
the
skills
of
software
programmer
statistician
and
storyteller
artist
to
extract
the
nuggets
of
gold
hidden
under
mountains
of
data
june
2010
mike
loukides
writes
in
what
is
data
science
data
scientists
combine
entrepreneurship
with
patience
the
willingness
to
build
data
products
incrementally
the
ability
to
explore
and
the
ability
to
iterate
over
a
solution
they
are
inherently
interdisciplinary
they
can
tackle
all
aspects
of
a
problem
from
initial
data
collection
and
data
conditioning
to
drawing
conclusions
they
can
think
outside
the
box
to
come
up
with
new
ways
to
view
the
problem
or
to
work
with
very
broadly
defined
problems
here
s
a
lot
of
data
what
can
you
make
from
it
september
2010
hilary
mason
and
chris
wiggins
write
in
a
taxonomy
of
data
science
we
thought
it
would
be
useful
to
propose
one
possible
taxonomy
of
what
a
data
scientist
does
in
roughly
chronological
order
obtain
scrub
explore
model
and
interpret
data
science
is
clearly
a
blend
of
the
hackers
arts
statistics
and
machine
learning
and
the
expertise
in
mathematics
and
the
domain
of
the
data
for
the
analysis
to
be
interpretable
it
requires
creative
decisions
and
open
mindedness
in
a
scientific
context
source
drew
conway
september
2010
drew
conway
writes
in
the
data
science
venn
diagram
one
needs
to
learn
a
lot
as
they
aspire
to
become
a
fully
competent
data
scientist
unfortunately
simply
enumerating
texts
and
tutorials
does
not
untangle
the
knots
therefore
in
an
effort
to
simplify
the
discussion
and
add
my
own
thoughts
to
what
is
already
a
crowded
market
of
ideas
i
present
the
data
science
venn
diagram
hacking
skills
math
and
stats
knowledge
and
substantive
expertise
may
2011
pete
warden
writes
in
why
the
term
data
science
is
flawed
but
useful
there
is
no
widely
accepted
boundary
for
what
s
inside
and
outside
of
data
science
s
scope
is
it
just
a
faddish
rebranding
of
statistics
i
don
t
think
so
but
i
also
don
t
have
a
full
definition
i
believe
that
the
recent
abundance
of
data
has
sparked
something
new
in
the
world
and
when
i
look
around
i
see
people
with
shared
characteristics
who
don
t
fit
into
traditional
categories
these
people
tend
to
work
beyond
the
narrow
specialties
that
dominate
the
corporate
and
institutional
world
handling
everything
from
finding
the
data
processing
it
at
scale
visualizing
it
and
writing
it
up
as
a
story
they
also
seem
to
start
by
looking
at
what
the
data
can
tell
them
and
then
picking
interesting
threads
to
follow
rather
than
the
traditional
scientist
s
approach
of
choosing
the
problem
first
and
then
finding
data
to
shed
light
on
it
may
2011
david
smith
writes
in
data
science
what
s
in
a
name
the
terms
data
science
and
data
scientist
have
only
been
in
common
usage
for
a
little
over
a
year
but
they
ve
really
taken
off
since
then
many
companies
are
now
hiring
for
data
scientists
and
entire
conferences
are
run
under
the
name
of
data
science
but
despite
the
widespread
adoption
some
have
resisted
the
change
from
the
more
traditional
terms
like
statistician
or
quant
or
data
analyst
i
think
data
science
better
describes
what
we
actually
do
a
combination
of
computer
hacking
data
analysis
and
problem
solving
june
2011
matthew
j
graham
talks
at
the
astrostatistics
and
data
mining
in
large
astronomical
databases
workshop
about
the
art
of
data
science
pdf
he
says
to
flourish
in
the
new
data
intensive
environment
of
21st
century
science
we
need
to
evolve
new
skills
we
need
to
understand
what
rules
data
obeys
how
it
is
symbolized
and
communicated
and
what
its
relationship
to
physical
space
and
time
is
september
2011
harlan
harris
writes
in
data
science
moore
s
law
and
moneyball
data
science
is
defined
as
what
data
scientists
do
what
data
scientists
do
has
been
very
well
covered
and
it
runs
the
gamut
from
data
collection
and
munging
through
application
of
statistics
and
machine
learning
and
related
techniques
to
interpretation
communication
and
visualization
of
the
results
who
data
scientists
are
may
be
the
more
fundamental
question
i
tend
to
like
the
idea
that
data
science
is
defined
by
its
practitioners
that
it
s
a
career
path
rather
than
a
category
of
activities
in
my
conversations
with
people
it
seems
that
people
who
consider
themselves
data
scientists
typically
have
eclectic
career
paths
that
might
in
some
ways
seem
not
to
make
much
sense
september
2011
d
j
patil
writes
in
building
data
science
teams
starting
in
2008
jeff
hammerbacher
hackingdata
and
i
sat
down
to
share
our
experiences
building
the
data
and
analytics
groups
at
facebook
and
linkedin
in
many
ways
that
meeting
was
the
start
of
data
science
as
a
distinct
professional
specialization
we
realized
that
as
our
organizations
grew
we
both
had
to
figure
out
what
to
call
the
people
on
our
teams
business
analyst
seemed
too
limiting
data
analyst
was
a
contender
but
we
felt
that
title
might
limit
what
people
could
do
after
all
many
of
the
people
on
our
teams
had
deep
engineering
expertise
research
scientist
was
a
reasonable
job
title
used
by
companies
like
sun
hp
xerox
yahoo
and
ibm
however
we
felt
that
most
research
scientists
worked
on
projects
that
were
futuristic
and
abstract
and
the
work
was
done
in
labs
that
were
isolated
from
the
product
development
teams
it
might
take
years
for
lab
research
to
affect
key
products
if
it
ever
did
instead
the
focus
of
our
teams
was
to
work
on
data
applications
that
would
have
an
immediate
and
massive
impact
on
the
business
the
term
that
seemed
to
fit
best
was
data
scientist
those
who
use
both
data
and
science
to
create
something
new
september
2012
tom
davenport
and
d
j
patil
publish
data
scientist
the
sexiest
job
of
the
21st
century
in
the
harvard
business
review
an
earlier
version
of
this
timeline
was
published
in
whatsthebigdata
com
see
also
a
very
short
history
of
big
data
and
a
very
short
history
of
information
technology
follow
me
on
twitter
gilpress
or
facebook
or
google
i
m
managing
partner
at
gpress
a
marketing
publishing
research
and
education
consultancy
previously
i
held
senior
marketing
and
research
management
positions
at
i
m
managing
partner
at
gpress
a
marketing
publishing
research
and
education
consultancy
previously
i
held
senior
marketing
and
research
management
positions
at
i
m
managing
partner
at
gpress
a
marketing
publishing
research
and
education
consultancy
previously
i
held
senior
marketing
and
research
management
positions
at
norc
dec
and
emc
most
recently
i
was
senior
director
thought
leadership
marketing
at
emc
where
i
launched
the
big
data
conversation
with
the
how
much
information
study
2000
with
uc
berkeley
and
the
digital
universe
study
2007
with
idc
twitter
gilpress
i
m
managing
partner
at
gpress
a
marketing
publishing
research
and
education
consultancy
previously
i
held
senior
marketing
and
research
management
positions
at
norc
dec
and
emc
most
recently
i
was
senior
director
thought
leadership
marketing
at
emc
where
i
launched
the
big
data
conversation
with
the
how
much
information
study
2000
with
uc
berkeley
and
the
digital
universe
study
2007
with
idc
twitter
gilpress